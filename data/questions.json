{
  "foundations-01": {
    "title": "Foundations of AI - Probability Theory",
    "questions": [
      {
        "id": 1,
        "topic": "Sources of Uncertainty",
        "difficulty": "recall",
        "question": "In the context of Data Science, which of the following is identified as a primary reason why models may be uncertain even if the underlying data acquisition is perfect?",
        "options": [
          "The use of frequentist instead of Bayesian priors",
          "Insufficient data volume to represent complex patterns",
          "The deterministic nature of human labels",
          "The sample space being larger than the event space"
        ],
        "correct_index": 1,
        "rationale": "As per the slides, models can be uncertain due to insufficient data, even if the data itself is captured accurately.",
        "distractor_analysis": {
          "0": "Priors are a choice of framework, not an inherent source of model uncertainty caused by data limits.",
          "1": "Correct. Limited data prevents the model from converging on a stable representation.",
          "2": "The slides state labels are stochastic and often ambiguous, not deterministic.",
          "3": "The event space is typically the power set of the sample space, making it larger or equal, not the other way around."
        }
      },
      {
        "id": 2,
        "topic": "Probability Space",
        "difficulty": "analysis",
        "question": "If an event space E is defined as the power set of a finite sample space Ω (E = 2^Ω), what is the implication for the probability measure P?",
        "options": [
          "P must map every possible subset of Ω to a value between 0 and 1",
          "P only assigns probabilities to elementary events, not their combinations",
          "The sum of probabilities of all elements in E must equal 1",
          "P is restricted to mapping events to either 0 or 1 exclusively"
        ],
        "correct_index": 0,
        "rationale": "By definition, P: E -> [0, 1] maps every event in the event space (which are subsets of Ω) to a probability value.",
        "distractor_analysis": {
          "0": "Correct. The probability measure must be defined for all sets in the event space.",
          "1": "P maps events (sets), which include combinations of elementary outcomes.",
          "2": "The sum of probabilities of elementary outcomes in Ω equals 1, not the sum of the whole power set.",
          "3": "This describes a deterministic assignment, whereas probability allows any value in the interval [0,1]."
        }
      },
      {
        "id": 3,
        "topic": "Probability Properties",
        "difficulty": "application",
        "question": "In a scenario where events A and B overlap, why is P(A ∩ B) subtracted in the formula for P(A ∪ B)?",
        "options": [
          "To account for the conditional dependence of B on A",
          "Because the intersection represents the 'impossible event' in a disjoint set",
          "To avoid double-counting the outcomes that belong to both sets",
          "To normalize the total probability so it does not exceed the value of the median"
        ],
        "correct_index": 2,
        "rationale": "The slides explicitly state that the common space is counted twice when adding P(A) and P(B), so it must be removed once.",
        "distractor_analysis": {
          "0": "The formula P(A ∪ B) = P(A) + P(B) - P(A ∩ B) applies regardless of dependence.",
          "1": "If they overlap, the intersection is not an impossible event (probability zero).",
          "2": "Correct. It corrects for the overlap in the Venn diagram logic.",
          "3": "Normalization ensures it doesn't exceed 1, which is the value of P(Ω), not the median."
        }
      },
      {
        "id": 4,
        "topic": "Bayes' Theorem",
        "difficulty": "analysis",
        "question": "When applying Bayes' Theorem, what happens to the posterior probability if the 'Evidence' P(A) increases while the likelihood and prior remain constant?",
        "options": [
          "The posterior probability increases proportionally",
          "The posterior probability decreases",
          "The posterior probability remains unchanged as it only depends on the likelihood",
          "The relationship is non-monotonic and depends on the sample space size"
        ],
        "correct_index": 1,
        "rationale": "In P(B|A) = [P(A|B)P(B)] / P(A), the Evidence P(A) is in the denominator. Increasing the denominator decreases the quotient.",
        "distractor_analysis": {
          "0": "Since P(A) is the denominator, its increase leads to a decrease in the result.",
          "1": "Correct. Higher evidence for a general occurrence makes a specific cause B less likely for that specific event.",
          "2": "The posterior is defined by the full ratio including the Evidence.",
          "3": "The formula dictates a clear inverse relationship with the denominator."
        }
      },
      {
        "id": 5,
        "topic": "Conditional Independence",
        "difficulty": "analysis",
        "question": "Two events A and B are independent. If they are now conditioned on a third event C, what can be definitively said about their relationship?",
        "options": [
          "They are guaranteed to remain independent given C",
          "They will always become dependent given C",
          "Independence does not automatically imply conditional independence",
          "Conditional independence only exists if C is the empty set"
        ],
        "correct_index": 2,
        "rationale": "The slides pose the question 'If A and B are independent, are they also independent given C?'. In probability theory, independence and conditional independence are distinct properties.",
        "distractor_analysis": {
          "0": "This is a common misconception; conditioning can introduce dependencies (e.g., explaining-away effect).",
          "1": "They might remain independent, but it is not guaranteed.",
          "2": "Correct. One does not strictly follow from the other.",
          "3": "Empty sets have probability 0, which makes conditional probability undefined."
        }
      },
      {
        "id": 6,
        "topic": "Simpson's Paradox",
        "difficulty": "application",
        "question": "In the provided Simpson’s Paradox example regarding drug efficacy, why does Drug X appear better when looking at subgroups, but Drug Y appears better in the aggregate?",
        "options": [
          "Drug Y has a higher success rate for both men and women individually",
          "The male subgroup has a significantly higher recovery rate and a strong bias toward one drug",
          "The sample size for women was too small to be statistically significant",
          "Drug X was only tested on patients who were already recovering"
        ],
        "correct_index": 1,
        "rationale": "The slides note that being male is a strong cause for both drug usage (Drug Y) and recovery, skewing the weighted average.",
        "distractor_analysis": {
          "0": "In the table, Drug X has higher rates in both subgroups (0.10 vs 0.05 and 0.91 vs 0.50).",
          "1": "Correct. The imbalance in how drugs were assigned across genders with different baseline recovery rates causes the paradox.",
          "2": "The paradox persists regardless of the 'significance' if the weightings are imbalanced.",
          "3": "While true that recovery rates differed, the key is the 'strong cause' of the gender variable on both recovery and drug choice."
        }
      },
      {
        "id": 7,
        "topic": "Random Variables",
        "difficulty": "recall",
        "question": "What is the primary condition that distinguishes a discrete random variable from a continuous one?",
        "options": [
          "The range of the variable must be a subset of Integers",
          "The mapping space M must be countable",
          "The probability of any single outcome must be exactly 0.5",
          "The variable must be independent and identically distributed (i.i.d.)"
        ],
        "correct_index": 1,
        "rationale": "Slide 11 states: 'If M is countable, X is called discrete, otherwise continuous.'",
        "distractor_analysis": {
          "0": "Discrete variables can be non-integers as long as they are countable.",
          "1": "Correct. Countability is the defining mathematical property here.",
          "2": "This is a specific property of a fair Bernoulli trial, not a general definition.",
          "3": "i.i.d. describes a relationship between multiple variables, not the type of a single variable."
        }
      },
      {
        "id": 8,
        "topic": "Probability Density Functions (PDF)",
        "difficulty": "analysis",
        "question": "For a continuous random variable X, why is the value of the PDF f(x) not equal to the probability P(X = x)?",
        "options": [
          "Because the sum of probabilities for continuous variables must be infinite",
          "The probability of any specific point in a continuous distribution is zero",
          "The PDF represents the cumulative area from negative infinity to x",
          "Continuous variables do not have outcomes, only ranges"
        ],
        "correct_index": 1,
        "rationale": "In continuous distributions, probability is defined over intervals. The probability at a single point is the integral from x to x, which is zero.",
        "distractor_analysis": {
          "0": "The total probability (integral) must equal 1.",
          "1": "Correct. The PDF represents density; probability is the area under the curve.",
          "2": "That is the definition of the CDF (Cumulative Distribution Function).",
          "3": "They have outcomes, but the outcomes exist on a continuum where P(X=x) vanishes."
        }
      },
      {
        "id": 9,
        "topic": "Quantile Function",
        "difficulty": "recall",
        "question": "Which specific value of the quantile function F^-1(q) corresponds to the median of a distribution?",
        "options": [
          "q = 0",
          "q = 1",
          "q = 0.5",
          "q = Mean / Variance"
        ],
        "correct_index": 2,
        "rationale": "Slide 13 explicitly defines the median as F^-1(q) for q = 0.5.",
        "distractor_analysis": {
          "0": "This would be the minimum of the support (if it exists).",
          "1": "This would be the maximum of the support.",
          "2": "Correct. The 0.5 quantile is the definition of the median.",
          "3": "This is an arbitrary ratio with no standard relation to the median."
        }
      },
      {
        "id": 10,
        "topic": "Bernoulli Distribution",
        "difficulty": "application",
        "question": "A Bernoulli distribution is used to model a single coin toss. If we extend this to model the total number of heads in 'm' independent tosses, which distribution do we transition to?",
        "options": [
          "Geometric Distribution",
          "Poisson Distribution",
          "Binomial Distribution",
          "Multinomial Distribution"
        ],
        "correct_index": 2,
        "rationale": "The Binomial distribution models the number of successes (heads) in m independent Bernoulli trials.",
        "distractor_analysis": {
          "0": "Geometric models the number of trials until the first success occurs.",
          "1": "Poisson models the number of events in a fixed interval of time/space.",
          "2": "Correct. A Binomial is the sum of i.i.d. Bernoulli variables.",
          "3": "Multinomial is for outcomes with more than two categories (e.g., dice)."
        }
      },
      {
        "id": 11,
        "topic": "Geometric Distribution",
        "difficulty": "analysis",
        "question": "In a Geometric distribution with parameter 'p', what does a very small 'p' value imply about the expected number of trials 'k' until success?",
        "options": [
          "Success is likely to happen in the very first trial",
          "The number of trials 'k' is likely to be very large",
          "The probability distribution becomes a Uniform distribution",
          "The variance of the distribution will approach zero"
        ],
        "correct_index": 1,
        "rationale": "If the probability of success per trial is low (small p), you expect to wait longer (more trials k) for the first success.",
        "distractor_analysis": {
          "0": "Small p means success is rare, making early success unlikely.",
          "1": "Correct. Lower p shifts the probability mass toward larger values of k.",
          "2": "A Geometric distribution is always decaying; it never becomes Uniform.",
          "3": "Lower probability of success generally increases the spread/uncertainty of when it will occur."
        }
      },
      {
        "id": 12,
        "topic": "Poisson Process",
        "difficulty": "application",
        "question": "You are modeling the number of phone calls received per hour. If the expected number of calls (λ) increases, how does the shape of the Poisson distribution change?",
        "options": [
          "It becomes more skewed toward zero",
          "It stays centered at zero but becomes taller",
          "It becomes more symmetric and bell-shaped",
          "It transforms into a Bernoulli distribution"
        ],
        "correct_index": 2,
        "rationale": "Slide 17 shows that as λ increases (from 0.5 to 10), the distribution shifts right and becomes more symmetric (approaching a Gaussian shape).",
        "distractor_analysis": {
          "0": "Smaller λ values are more skewed toward zero.",
          "1": "The peak (mode) shifts with λ, it doesn't stay at zero.",
          "2": "Correct. This is a property of the Poisson distribution as λ grows.",
          "3": "A Poisson distribution is for counts (0 to infinity), while Bernoulli is only 0 or 1."
        }
      },
      {
        "id": 13,
        "topic": "Exponential Distribution",
        "difficulty": "analysis",
        "question": "The 'memoryless' property of the Exponential distribution implies that:",
        "options": [
          "The probability of failure increases the longer a device has been running",
          "The remaining waiting time is independent of how much time has already passed",
          "The distribution has no variance, making it easy to predict",
          "Past events determine the exact timing of the next event"
        ],
        "correct_index": 1,
        "rationale": "Slide 18 states P(X > a + b | X > a) = P(X > b), meaning the probability of waiting 'b' more units is the same regardless of the 'a' units already waited.",
        "distractor_analysis": {
          "0": "This would describe a distribution with 'wear-out', which the Exponential specifically lacks.",
          "1": "Correct. This is the definition of memorylessness.",
          "2": "Exponential distributions have high variance (equal to 1/λ^2).",
          "3": "This contradicts the 'independent' part of the Poisson/Exponential process."
        }
      },
      {
        "id": 14,
        "topic": "Pareto Distribution",
        "difficulty": "recall",
        "question": "The Pareto distribution is often used to model which type of phenomenon?",
        "options": [
          "Events that occur at a constant average rate over time",
          "Power-law distributions where a small percentage of causes lead to most effects",
          "Symmetric outcomes like height or weight in a population",
          "Binary outcomes where success and failure are equally likely"
        ],
        "correct_index": 1,
        "rationale": "Slide 19 links the Pareto distribution to the '80/20' principle and power-law distributions (wealth, populations, followers).",
        "distractor_analysis": {
          "0": "This describes a Poisson or Exponential process.",
          "1": "Correct. It is the mathematical model for heavy-tailed phenomena.",
          "2": "Symmetric outcomes are modeled by Gaussian distributions.",
          "3": "This is a Bernoulli trial with p = 0.5."
        }
      },
      {
        "id": 15,
        "topic": "Logistic Distribution",
        "difficulty": "application",
        "question": "In which field is the Logistic cumulative distribution function most commonly applied as an 'activation' or inference tool?",
        "options": [
          "Modeling radioactive decay",
          "Neural Networks and Classification",
          "Determining the median of a Pareto distribution",
          "Calculating the number of heads in 100 coin tosses"
        ],
        "correct_index": 1,
        "rationale": "Slide 20 lists 'Inference in neural networks' and 'Classification' as primary applications.",
        "distractor_analysis": {
          "0": "Radioactive decay is modeled by the Exponential distribution.",
          "1": "Correct. The sigmoid shape is fundamental to logistic regression and ML.",
          "2": "These are different distribution types with distinct functional forms.",
          "3": "This is modeled by the Binomial distribution."
        }
      },
      {
        "id": 16,
        "topic": "Normal (Gaussian) Distribution",
        "difficulty": "analysis",
        "question": "How does increasing the standard deviation (σ) affect the Probability Density Function (PDF) of a Normal distribution?",
        "options": [
          "The peak shifts to the right on the x-axis",
          "The peak becomes taller and narrower",
          "The curve becomes flatter and wider, but the area remains 1",
          "The distribution becomes skewed to the left"
        ],
        "correct_index": 2,
        "rationale": "Standard deviation measures spread. A higher σ spreads the probability mass over a wider range, lowering the peak to maintain a total area of 1.",
        "distractor_analysis": {
          "0": "The mean (μ) shifts the peak, not σ.",
          "1": "This happens when σ decreases.",
          "2": "Correct. This represents increased uncertainty or variance.",
          "3": "The Normal distribution is always perfectly symmetric around its mean."
        }
      },
      {
        "id": 17,
        "topic": "Multivariate Distributions",
        "difficulty": "recall",
        "question": "What is the result of marginalizing a Joint PDF of several random variables?",
        "options": [
          "A single probability value (scalar)",
          "A distribution that depends only on a subset of the original variables",
          "A conditional distribution given the excluded variables",
          "The covariance matrix of the variables"
        ],
        "correct_index": 1,
        "rationale": "Slide 22 shows that marginalization (summing or integrating out variables) results in a distribution for the remaining variables (e.g., f_Xi(xi)).",
        "distractor_analysis": {
          "0": "Marginalization results in a function (PDF), not a single number, unless all variables are integrated out.",
          "1": "Correct. It effectively 'ignores' the variation of the other variables.",
          "2": "Conditional distributions are found by dividing the joint by the marginal, not just by marginalizing.",
          "3": "The covariance matrix is a summary statistic, not the marginalized distribution itself."
        }
      },
      {
        "id": 18,
        "topic": "Multivariate Gaussian",
        "difficulty": "analysis",
        "question": "In a Multivariate Gaussian distribution, what do the off-diagonal elements of the Σ (Sigma) matrix represent?",
        "options": [
          "The means of each individual variable",
          "The variance of each individual variable",
          "The covariance between pairs of variables",
          "The weights of the Gaussian mixture"
        ],
        "correct_index": 2,
        "rationale": "Slide 23 defines Σ_ij as Cov(Xi, Xj). The diagonal contains variances (i=j), and off-diagonals contain covariances (i≠j).",
        "distractor_analysis": {
          "0": "Means are stored in the μ vector.",
          "1": "Variances are on the diagonal of Σ.",
          "2": "Correct. They indicate how much two variables change together.",
          "3": "Weights are used in Mixture Models (GMM), not a single Multivariate Gaussian."
        }
      },
      {
        "id": 19,
        "topic": "Multinomial Distribution",
        "difficulty": "application",
        "question": "Which scenario would be best modeled using a Multinomial distribution?",
        "options": [
          "Predicting the outcome of a single fair coin toss",
          "Counting the number of '6's rolled in 10 tosses of a standard die",
          "Counting how many times each face (1 through 6) appears after rolling a die 50 times",
          "Determining the time between arrivals of customers at a bank"
        ],
        "correct_index": 2,
        "rationale": "The Multinomial distribution is for n trials with more than two possible outcomes per trial (e.g., rolling n m-sided dice).",
        "distractor_analysis": {
          "0": "This is a Bernoulli distribution.",
          "1": "This is a Binomial distribution (success '6' vs failure 'not 6').",
          "2": "Correct. It handles the counts for all possible faces simultaneously.",
          "3": "This is an Exponential distribution."
        }
      },
      {
        "id": 20,
        "topic": "Expectation Properties",
        "difficulty": "analysis",
        "question": "If two random variables X and Y are uncorrelated, which property of Expectation is guaranteed to hold?",
        "options": [
          "E(X + Y) = E(X) + E(Y)",
          "E(XY) = E(X)E(Y)",
          "E(X / Y) = E(X) / E(Y)",
          "E(X^2) = E(X)^2"
        ],
        "correct_index": 1,
        "rationale": "Slide 24 notes that E(XY) = E(X)E(Y) for independent variables, and variables for which this holds are called uncorrelated.",
        "distractor_analysis": {
          "0": "This property (linearity) holds for all random variables, regardless of correlation.",
          "1": "Correct. This is the definition/implication of being uncorrelated.",
          "2": "Expectation does not distribute over division.",
          "3": "This only holds if the variance is zero (X is a constant)."
        }
      },
      {
        "id": 21,
        "topic": "Variance Properties",
        "difficulty": "application",
        "question": "What is the variance of the sum of two variables X and Y [Var(X + Y)] if they are perfectly positively correlated?",
        "options": [
          "Var(X) + Var(Y)",
          "Var(X) + Var(Y) + 2Cov(X, Y)",
          "Var(X) - Var(Y)",
          "0"
        ],
        "correct_index": 1,
        "rationale": "Slide 25 gives the general formula: Var(X + Y) = Var(X) + Var(Y) + 2Cov(X, Y).",
        "distractor_analysis": {
          "0": "This only holds if they are uncorrelated (Cov = 0).",
          "1": "Correct. This is the general expansion including the interaction term.",
          "2": "This is not a standard variance expansion formula.",
          "3": "Variance is only zero for constant values, not for correlated variables."
        }
      },
      {
        "id": 22,
        "topic": "Frequentist View",
        "difficulty": "recall",
        "question": "What is the primary shortcoming of the Frequentist view of probability as identified in the slides?",
        "options": [
          "It relies too heavily on subjective prior beliefs",
          "It can only be applied to events that are frequently repeatable",
          "It fails when the number of trials approaches infinity",
          "It assumes that all outcomes are equally likely in every scenario"
        ],
        "correct_index": 1,
        "rationale": "Slide 26 states a shortcoming: 'Can be only applied to frequently repeatable events.'",
        "distractor_analysis": {
          "0": "This is a characteristic (often viewed as a drawback) of the Bayesian view.",
          "1": "Correct. It cannot handle 'one-off' events where frequency can't be measured.",
          "2": "Frequentist estimates actually become more meaningful as n -> infinity.",
          "3": "This describes the 'classical' definition, not the frequentist 'relative frequency' approach."
        }
      },
      {
        "id": 23,
        "topic": "Bayesian View",
        "difficulty": "analysis",
        "question": "In the Bayesian view, what happens to the influence of the 'Prior' as the number of new observations increases?",
        "options": [
          "The prior becomes more relevant as more data justifies it",
          "The prior remains equally influential regardless of data size",
          "The prior becomes less and less relevant",
          "The prior is discarded and replaced by the evidence"
        ],
        "correct_index": 2,
        "rationale": "Slide 27 states: 'With increasing number of observations, prior beliefs become less and less relevant (i.e., uncertainty is reduced).'",
        "distractor_analysis": {
          "0": "The likelihood begins to dominate the posterior calculation with more data.",
          "1": "The weight of evidence overcomes the initial belief.",
          "2": "Correct. Data 'washes out' the influence of the starting prior.",
          "3": "It is not discarded; its weight in the product P(likelihood)*P(prior) simply diminishes relative to the likelihood."
        }
      },
      {
        "id": 24,
        "topic": "Cox’s Theorem",
        "difficulty": "recall",
        "question": "According to Cox’s Theorem, if a belief system is 'consistent', what must be true?",
        "options": [
          "Beliefs must be updated using only MLE",
          "If a belief can be derived in many ways, all results must be equal",
          "Beliefs can only be represented by integers",
          "The belief must not change with new observations"
        ],
        "correct_index": 1,
        "rationale": "Slide 28 explicitly defines consistency as: 'If the belief... can be derived in many ways, all the results must be equal.'",
        "distractor_analysis": {
          "0": "Cox's theorem provides a foundation for probability theory, not specifically MLE.",
          "1": "Correct. Consistency implies paths to the same conclusion must yield the same value.",
          "2": "Cox's theorem states beliefs should be represented by real numbers (Numerical Comparability).",
          "3": "This would violate 'Common Sense', which says beliefs should change sensibly with observations."
        }
      },
      {
        "id": 25,
        "topic": "Bayesian Inference",
        "difficulty": "analysis",
        "question": "Which component of Bayesian Inference is typically ignored when finding the most likely parameters (Maximum A Posteriori) because it acts only as a normalization constant?",
        "options": [
          "Prior",
          "Likelihood",
          "Evidence",
          "Posterior"
        ],
        "correct_index": 2,
        "rationale": "Slide 29 shows the proportionality: Posterior ∝ Likelihood * Prior. The Evidence P(x) is the denominator that normalizes the distribution.",
        "distractor_analysis": {
          "0": "The prior is essential to the Bayesian calculation.",
          "1": "The likelihood represents the data's contribution and is essential.",
          "2": "Correct. Since P(x) does not depend on the parameters θ, it is ignored during maximization.",
          "3": "The posterior is the result we are trying to find/maximize."
        }
      },
      {
        "id": 26,
        "topic": "Conjugate Priors",
        "difficulty": "recall",
        "question": "What is the primary 'algebraic convenience' provided by using a conjugate prior?",
        "options": [
          "It ensures that the likelihood is always Gaussian",
          "The posterior distribution will be in the same family as the prior",
          "It eliminates the need for any likelihood function",
          "It guarantees that the MLE and Bayesian estimate will be identical"
        ],
        "correct_index": 1,
        "rationale": "Slide 30 defines a conjugate prior as one where the posterior is in the same pdf family as the prior.",
        "distractor_analysis": {
          "0": "Conjugacy exists for many families (Beta, Gamma, etc.), not just Gaussian.",
          "1": "Correct. This allows for easy iterative updates as more data arrives.",
          "2": "You still need a likelihood; conjugacy is a property of the prior with respect to a likelihood.",
          "3": "They are usually different because the prior shifts the Bayesian estimate."
        }
      },
      {
        "id": 27,
        "topic": "Maximum Likelihood Estimation (MLE)",
        "difficulty": "recall",
        "question": "What is the core objective of Maximum Likelihood Estimation?",
        "options": [
          "To find the parameters that make the observed data most probable",
          "To calculate the prior probability of the parameters",
          "To minimize the variance of the sample space",
          "To ensure the model is unbiased and perfectly accurate"
        ],
        "correct_index": 0,
        "rationale": "MLE seeks parameters θ that maximize L(θ) = P(Data | θ).",
        "distractor_analysis": {
          "0": "Correct. It picks the θ that 'explains' the data best.",
          "1": "MLE is a frequentist approach and typically does not use priors.",
          "2": "MLE maximizes a likelihood function; it doesn't inherently minimize sample variance.",
          "3": "MLE is not always unbiased (e.g., the MLE for variance is biased)."
        }
      },
      {
        "id": 28,
        "topic": "Log-Likelihood",
        "difficulty": "analysis",
        "question": "Why is it common practice to maximize the log-likelihood rather than the likelihood itself?",
        "options": [
          "Logarithms change the location of the maximum to a more stable point",
          "It turns products of probabilities into sums, simplifying differentiation",
          "The log-likelihood is always convex, whereas the likelihood is not",
          "Logarithms remove the influence of outliers in the data"
        ],
        "correct_index": 1,
        "rationale": "Likelihoods for i.i.d. data involve large products. Logarithms convert these to sums, which are mathematically easier to handle when taking derivatives.",
        "distractor_analysis": {
          "0": "The log function is monotonic; it preserves the location of the maximum.",
          "1": "Correct. This is a fundamental computational trick in statistics/ML.",
          "2": "Not necessarily. If the likelihood is non-convex, the log-likelihood is likely also non-convex.",
          "3": "Logarithms do not change the data; they just change the scale of the optimization function."
        }
      },
      {
        "id": 29,
        "topic": "MLE for Gaussian",
        "difficulty": "application",
        "question": "If you have a set of i.i.d. samples from a Gaussian distribution, what is the MLE for the mean (μ)?",
        "options": [
          "The median of the samples",
          "The arithmetic average of the samples",
          "The square root of the variance",
          "The value of the first observation x1"
        ],
        "correct_index": 1,
        "rationale": "Slide 33 derives the MLE for μ as (1/n) * Σ(xi), which is the sample mean (arithmetic average).",
        "distractor_analysis": {
          "0": "The median is a robust estimator but not the MLE for a standard Gaussian mean.",
          "1": "Correct. It is the most 'likely' center point given the data.",
          "2": "This is related to the standard deviation, not the mean.",
          "3": "The first observation ignores the rest of the evidence in the dataset."
        }
      },
      {
        "id": 30,
        "topic": "MLE Generalization",
        "difficulty": "analysis",
        "question": "When is MLE considered 'analytically intractable', necessitating iterative methods like Expectation-Maximization?",
        "options": [
          "When the sample size n is less than 30",
          "When the derivative of the log-likelihood cannot be solved for zero in closed form",
          "Whenever a prior distribution is included in the model",
          "If the data is perfectly clean and has no noise"
        ],
        "correct_index": 1,
        "rationale": "Slide 34 states: 'If ∂ log L / ∂ p is analytically intractable, use iterative numerical methods...'",
        "distractor_analysis": {
          "0": "Intractability refers to the mathematical form, not the sample size.",
          "1": "Correct. If you can't solve it with a formula, you must search for it numerically.",
          "2": "MLE doesn't include priors; that would lead to MAP (Maximum A Posteriori).",
          "3": "Clean data usually makes MLE easier, not harder."
        }
      },
      {
        "id": 31,
        "topic": "Gaussian Mixture Models (GMM)",
        "difficulty": "recall",
        "question": "What defines a Gaussian Mixture Model compared to a standard Gaussian distribution?",
        "options": [
          "It uses a single mean but multiple variance parameters",
          "It represents the data as being generated from a weighted sum of several Gaussians",
          "It is only used for discrete random variables",
          "It is a Bayesian method that requires a Beta prior"
        ],
        "correct_index": 1,
        "rationale": "Slide 35 describes a mixture of Gaussians with weights (pA, pB) and individual parameters (μ, σ).",
        "distractor_analysis": {
          "0": "Each component in a mixture has its own mean and its own variance.",
          "1": "Correct. It allows modeling complex, multi-modal distributions.",
          "2": "GMMs are continuous mixture models.",
          "3": "GMM parameters can be estimated using frequentist methods like MLE/EM."
        }
      },
      {
        "id": 32,
        "topic": "EM for GMM",
        "difficulty": "analysis",
        "question": "Why is standard MLE usually impossible for finding the global maximum of a Gaussian Mixture Model likelihood?",
        "options": [
          "The likelihood function is always linear",
          "The likelihood function is non-convex and may have multiple local maxima",
          "GMMs do not have a likelihood function",
          "The sample size is always too small for GMMs"
        ],
        "correct_index": 1,
        "rationale": "Slide 36 states: 'likelihood function for GMMs is highly non-convex with multiple local maxima.'",
        "distractor_analysis": {
          "0": "Mixture models involve sums inside logs (after expanding), making them highly non-linear.",
          "1": "Correct. This non-convexity is why we need iterative algorithms like EM.",
          "2": "They have a well-defined likelihood; it's just hard to optimize.",
          "3": "GMMs can be used with any sample size, though results improve with more data."
        }
      },
      {
        "id": 33,
        "topic": "Expectation Step (E-step)",
        "difficulty": "application",
        "question": "In the E-step of the EM algorithm for mixture models, what is being estimated for each data point xi?",
        "options": [
          "The final parameters μ and σ",
          "The total probability of the entire dataset",
          "The 'membership weight' (the probability xi belongs to a specific cluster)",
          "The derivative of the likelihood with respect to the weights"
        ],
        "correct_index": 2,
        "rationale": "Slide 37/38: The E-step computes 'expected membership values' P(A|xi) and P(B|xi).",
        "distractor_analysis": {
          "0": "Parameters are updated in the M-step, not the E-step.",
          "1": "The likelihood is evaluated to check for convergence, but not the goal of the E-step.",
          "2": "Correct. This step 'assigns' data points to distributions based on current guesses.",
          "3": "Derivatives are part of the optimization logic in the M-step."
        }
      },
      {
        "id": 34,
        "topic": "Maximization Step (M-step)",
        "difficulty": "application",
        "question": "During the M-step of the EM algorithm, how are the parameters (μ, σ, p) updated?",
        "options": [
          "They are randomly perturbed to avoid local maxima",
          "They are recalculated using the membership weights found in the E-step",
          "They are held constant while the data labels are changed",
          "They are set to the values of the first observation x1"
        ],
        "correct_index": 1,
        "rationale": "Slide 38 shows that new parameters are 'weighted' averages of the data points, using weights (wAi) calculated in the E-step.",
        "distractor_analysis": {
          "0": "EM is a deterministic iterative algorithm; it doesn't use random perturbation.",
          "1": "Correct. The E-step provides the 'soft' assignments, and the M-step optimizes based on them.",
          "2": "The parameters are the things being updated in this step.",
          "3": "This would be a very poor estimator that ignores most data."
        }
      },
      {
        "id": 35,
        "topic": "EM Convergence",
        "difficulty": "analysis",
        "question": "Which statement best describes the convergence behavior of the EM algorithm?",
        "options": [
          "It is guaranteed to find the global maximum in a single iteration",
          "It monotonically approaches a local maximum of the likelihood",
          "It oscillates indefinitely and never truly converges",
          "It converges only if the initial parameters are perfectly accurate"
        ],
        "correct_index": 1,
        "rationale": "Slide 39: 'Note: EM monotonically approaches local maximum.'",
        "distractor_analysis": {
          "0": "It is iterative and, for non-convex functions, rarely finds the global maximum.",
          "1": "Correct. Each step is guaranteed not to decrease the likelihood.",
          "2": "Because it is monotonic, it cannot oscillate; it must level off.",
          "3": "It converges from almost any starting point, though the specific local maximum reached depends on the start."
        }
      },
      {
        "id": 36,
        "topic": "EM Generalization",
        "difficulty": "recall",
        "question": "In the general formulation of EM, what do the values 'z1, ..., zm' represent?",
        "options": [
          "Observed data points",
          "Hidden (latent) values",
          "Model parameters to be optimized",
          "Hyper-parameters for the Beta prior"
        ],
        "correct_index": 1,
        "rationale": "Slide 39 distinguishes between 'observed data points xi' and 'hidden values zj'.",
        "distractor_analysis": {
          "0": "Observed data is denoted as x.",
          "1": "Correct. EM is designed precisely to handle these unobserved variables.",
          "2": "Parameters are denoted as θ.",
          "3": "EM is usually described in a frequentist MLE context, not Bayesian hyper-parameters."
        }
      },
      {
        "id": 37,
        "topic": "Probability measure",
        "difficulty": "recall",
        "question": "A probability measure P maps an event to a number. What is the defined range of this number?",
        "options": [
          "(-∞, +∞)",
          "[0, 1]",
          "Any integer value",
          "[-1, 1]"
        ],
        "correct_index": 1,
        "rationale": "Slide 5 defines P: E -> [0, 1].",
        "distractor_analysis": {
          "0": "Probabilities cannot be negative or infinitely large.",
          "1": "Correct. This is a fundamental axiom of probability.",
          "2": "Probabilities are real numbers, not just integers.",
          "3": "Probabilities are never negative."
        }
      },
      {
        "id": 38,
        "topic": "Binomial vs Bernoulli",
        "difficulty": "analysis",
        "question": "If you set the parameter 'm = 1' in a Binomial distribution, what does it simplify to?",
        "options": [
          "A Poisson distribution",
          "A Bernoulli distribution",
          "A Uniform distribution",
          "A Gaussian distribution"
        ],
        "correct_index": 1,
        "rationale": "A Binomial distribution is the sum of m trials. With only 1 trial, it is by definition a Bernoulli trial.",
        "distractor_analysis": {
          "0": "Poisson is for an infinite number of possible outcomes (counts).",
          "1": "Correct. A single trial with two outcomes is Bernoulli.",
          "2": "Uniform requires all outcomes in the sample space to have equal probability, which is only a special case of Bernoulli (p=0.5).",
          "3": "Gaussian is continuous; Binomial is discrete."
        }
      },
      {
        "id": 39,
        "topic": "Uniform Distribution",
        "difficulty": "application",
        "question": "When rolling a fair 6-sided die, what is the probability of a single face according to the Discrete Uniform Distribution formula?",
        "options": [
          "1/2",
          "1/6",
          "1/m^2",
          "p^x * (1-p)^(1-x)"
        ],
        "correct_index": 1,
        "rationale": "Slide 14: Uniform distribution over {1...m} has P(X=k) = 1/m. For a die, m=6.",
        "distractor_analysis": {
          "0": "This would be for a 2-sided coin.",
          "1": "Correct. 1 divided by the total number of outcomes.",
          "2": "This is not a standard probability mass function formula.",
          "3": "This is the formula for a Bernoulli distribution."
        }
      },
      {
        "id": 40,
        "topic": "Joint Probability",
        "difficulty": "application",
        "question": "If P(A, B) = P(A) * P(B), what can we conclude about events A and B?",
        "options": [
          "They are mutually exclusive",
          "They are independent",
          "A is a subset of B",
          "P(A|B) must be zero"
        ],
        "correct_index": 1,
        "rationale": "The definition of independence for two events is that their joint probability is the product of their marginal probabilities (Slide 9).",
        "distractor_analysis": {
          "0": "Mutually exclusive events have P(A, B) = 0.",
          "1": "Correct. This is the mathematical definition of independence.",
          "2": "A being a subset would mean P(A, B) = P(A).",
          "3": "If they are independent, P(A|B) = P(A), not zero."
        }
      },
      {
        "id": 41,
        "topic": "Marginal Probability",
        "difficulty": "analysis",
        "question": "In the grid example (Slide 12), if you sum all joint probabilities P(X=xi, Y=yj) across all possible values of j, what do you obtain?",
        "options": [
          "The conditional probability P(Y|X)",
          "The marginal probability P(X=xi)",
          "The total probability of the entire sample space (1.0)",
          "The joint probability P(X, Y)"
        ],
        "correct_index": 1,
        "rationale": "The 'Sum Rule' (Slide 12) states that summing the joint probability over all Y yields the marginal for X.",
        "distractor_analysis": {
          "0": "Conditional probability requires dividing the joint by the marginal.",
          "1": "Correct. This is the definition of marginalization.",
          "2": "You would only get 1.0 if you summed over both i and j.",
          "3": "You are starting with the joint; the sum simplifies it."
        }
      },
      {
        "id": 42,
        "topic": "Conjugate Prior Examples",
        "difficulty": "recall",
        "question": "Which of the following is the correct conjugate prior for a Poisson likelihood?",
        "options": [
          "Beta",
          "Gamma",
          "Dirichlet",
          "Gaussian"
        ],
        "correct_index": 1,
        "rationale": "Slide 30 lists the Poisson likelihood's conjugate prior as Gamma.",
        "distractor_analysis": {
          "0": "Beta is for Bernoulli/Binomial.",
          "1": "Correct. Poisson and Gamma form a conjugate pair.",
          "2": "Dirichlet is for Multinomial.",
          "3": "Gaussian is its own conjugate prior."
        }
      },
      {
        "id": 43,
        "topic": "Uncorrelated vs Independent",
        "difficulty": "analysis",
        "question": "Which statement correctly describes the relationship between independence and correlation?",
        "options": [
          "Independent variables are always uncorrelated",
          "Uncorrelated variables are always independent",
          "Correlation and independence are exactly the same concept",
          "Only Gaussian variables can be independent"
        ],
        "correct_index": 0,
        "rationale": "Independence is a much stronger condition than zero correlation. If X and Y are independent, they are necessarily uncorrelated, but the reverse is not always true.",
        "distractor_analysis": {
          "0": "Correct. Independence implies no linear (or non-linear) relationship.",
          "1": "Variables can be uncorrelated (no linear relationship) but still have a non-linear dependency.",
          "2": "Correlation only measures linear dependency; independence measures all dependency.",
          "3": "Any type of random variable can be independent."
        }
      },
      {
        "id": 44,
        "topic": "Maximum Likelihood Logic",
        "difficulty": "analysis",
        "question": "If you toss a coin 'n' times and see 'k' heads, the MLE for the probability of heads 'p' is k/n. Why is this logically intuitive?",
        "options": [
          "It assumes the coin is always fair (0.5)",
          "It matches the observed relative frequency of the event",
          "It is the only value that makes the likelihood exactly 1.0",
          "It minimizes the chance of seeing any tails"
        ],
        "correct_index": 1,
        "rationale": "Slide 32 derives p = k/n. This matches the frequentist intuition that the best estimate of a probability is its occurrence rate in the sample.",
        "distractor_analysis": {
          "0": "MLE doesn't assume p=0.5; it estimates p from data.",
          "1": "Correct. It aligns the model's 'expected' rate with the 'observed' rate.",
          "2": "The likelihood at k/n is typically much less than 1.0; it's just the maximum possible value.",
          "3": "It doesn't minimize tails; it finds the balance that best fits the observed count of both heads and tails."
        }
      },
      {
        "id": 45,
        "topic": "Mixture Model Applications",
        "difficulty": "application",
        "question": "In a medical study of height and weight distribution (Slide 23/35), why might a Mixture Model be more appropriate than a single Multivariate Gaussian?",
        "options": [
          "Because height and weight are always independent",
          "Because the population may contain distinct subgroups (e.g., men and women) with different centers",
          "Because MLE can only be used with one variable at a time",
          "Because the sample size is likely too large for a single Gaussian"
        ],
        "correct_index": 1,
        "rationale": "Slide 35 explicitly mentions 'weights of women and men' as an example for mixture models, as they likely form two overlapping clusters.",
        "distractor_analysis": {
          "0": "Height and weight are usually highly correlated, not independent.",
          "1": "Correct. Mixtures account for sub-populations within the data.",
          "2": "MLE works for any number of variables (Multivariate MLE).",
          "3": "Gaussians handle large samples well; the issue is 'multi-modality' (multiple peaks)."
        }
      },
      {
        "id": 46,
        "topic": "EM Loop",
        "difficulty": "recall",
        "question": "What is the correct iterative loop for the EM algorithm for mixture models?",
        "options": [
          "E-step -> M-step -> Iterate until convergence",
          "M-step -> E-step -> Finalize parameters",
          "Prior -> Likelihood -> Evidence",
          "Sample -> Evaluate -> Discard"
        ],
        "correct_index": 0,
        "rationale": "Slide 37 defines the steps: 1. E-step, 2. M-step, 3. Iterate until convergence.",
        "distractor_analysis": {
          "0": "Correct. You need the E-step (assignments) to perform the M-step (updates).",
          "1": "You cannot perform a meaningful M-step without the E-step's membership weights.",
          "2": "This describes the components of Bayes' theorem, not an iterative algorithm loop.",
          "3": "This is not a standard description of any statistical algorithm in the slides."
        }
      },
      {
        "id": 47,
        "topic": "Cumulative Distribution Function (CDF)",
        "difficulty": "analysis",
        "question": "As x approaches positive infinity, what value must the Cumulative Distribution Function F(x) approach?",
        "options": [
          "0",
          "0.5",
          "1",
          "Infinity"
        ],
        "correct_index": 2,
        "rationale": "The CDF represents the total probability that X is less than or equal to x. As x covers the entire support, the probability must sum to 1.",
        "distractor_analysis": {
          "0": "The CDF approaches 0 as x goes to negative infinity.",
          "1": "This is only true at the median.",
          "2": "Correct. All probability mass is accounted for.",
          "3": "Probability values are capped at 1."
        }
      },
      {
        "id": 48,
        "topic": "Pareto Principle",
        "difficulty": "application",
        "question": "If a social network's follower distribution follows a Pareto distribution, what would you expect to observe?",
        "options": [
          "Most users have almost exactly the same number of followers",
          "A very small number of 'super-users' have the vast majority of all followers",
          "The number of followers is distributed as a bell curve centered at 500",
          "Users are either 'celebrities' (1M followers) or 'bots' (0 followers) with nothing in between"
        ],
        "correct_index": 1,
        "rationale": "Slide 19 explains the Pareto principle: 80% of effects (followers) come from 20% of causes (users). This is a heavy-tailed distribution.",
        "distractor_analysis": {
          "0": "This would be a distribution with very low variance (not Pareto).",
          "1": "Correct. This is the characteristic 'winner-take-all' nature of power-law distributions.",
          "2": "This would be a Gaussian distribution.",
          "3": "A Pareto distribution is continuous and covers all values, though higher values are rarer."
        }
      },
      {
        "id": 49,
        "topic": "MLE bias",
        "difficulty": "analysis",
        "question": "For a Gaussian distribution, the MLE for the variance (σ^2) is Σ(xi - μ)^2 / n. Why is this sometimes criticized in statistics compared to the 'sample variance' (which divides by n-1)?",
        "options": [
          "The MLE is always larger than the true variance",
          "The MLE is a biased estimator that tends to underestimate the true variance in small samples",
          "The MLE cannot be calculated if the mean is unknown",
          "The MLE requires the data to be independent"
        ],
        "correct_index": 1,
        "rationale": "While not explicitly in the slides, the formula on Slide 33 shows division by 'n'. In statistical theory, dividing by 'n' rather than 'n-1' makes the MLE biased for variance.",
        "distractor_analysis": {
          "0": "Dividing by a larger number (n) makes the result smaller, not larger.",
          "1": "Correct. This is a classic result in statistical theory regarding MLE bias.",
          "2": "MLE uses the estimated mean (μ-hat) to calculate variance.",
          "3": "The likelihood derivation itself assumes i.i.d. data."
        }
      },
      {
        "id": 50,
        "topic": "EM and Local Maxima",
        "difficulty": "analysis",
        "question": "If the EM algorithm is run multiple times on the same GMM problem but with different random initializations, what is a likely outcome?",
        "options": [
          "It will always converge to the exact same parameter values",
          "It may converge to different local maxima with different likelihood values",
          "It will fail to converge on all but one of the runs",
          "It will prove that the likelihood function is actually convex"
        ],
        "correct_index": 1,
        "rationale": "Because the GMM likelihood is non-convex (Slide 36), the algorithm's end point (local maximum) depends heavily on the starting point.",
        "distractor_analysis": {
          "0": "This only happens if there is only one peak (convexity).",
          "1": "Correct. This is why practitioners often use multiple restarts for EM.",
          "2": "EM is very robust in terms of convergence; it will converge to something almost every time.",
          "3": "Running an algorithm doesn't change the underlying mathematical shape of the function."
        }
      }
    ]
  },
  "foundations-02": {
    "title": "Foundations of AI - Statistics",
    "questions": [
      {
        "id": 1,
        "topic": "Sampling",
        "difficulty": "analysis",
        "question": "A researcher wants to study the average study time of students at a massive university. They decide to survey only students present in the main library on a Friday night. Which statement best describes the statistical implications of this sampling method?",
        "options": [
          "It represents a stratified sample because the library is a specific subpopulation.",
          "It is a convenience sample that likely introduces a positive bias toward study hours.",
          "The sample is unbiased because every student has the potential to be in the library.",
          "The law of large numbers will eventually correct the sampling bias as more students are surveyed in the library."
        ],
        "correct_index": 1,
        "rationale": "Sampling only those easily accessible (convenience sampling) often leads to a sample that does not represent the broader population. In this case, students in a library on a Friday night are likely to study more than the average student, leading to a biased estimate.",
        "distractor_analysis": {
          "0": "Stratified sampling requires deliberate partitioning of the entire population, not just picking one group.",
          "1": "Correct. This identifies the method (convenience) and the likely direction of bias.",
          "2": "Unbiasedness requires every element in the total population to have an equal (or known) probability of selection, which isn't true here.",
          "3": "The Law of Large Numbers ensures convergence to the *sample* mean's expected value, not the *population* mean if the sampling process is inherently biased."
        }
      },
      {
        "id": 2,
        "topic": "Sampling",
        "difficulty": "application",
        "question": "In a scenario where a population has highly distinct subgroups (e.g., different income levels) and you want to ensure each group is represented proportionally to its size, which sampling strategy is most appropriate?",
        "options": [
          "Systematic sampling",
          "Convenience sampling",
          "Stratified sampling",
          "Random sampling"
        ],
        "correct_index": 2,
        "rationale": "Stratified sampling involves dividing the population into subpopulations (strata) and sampling from each to ensure representation, especially when there is high variance between groups.",
        "distractor_analysis": {
          "0": "Systematic sampling follows a fixed interval (every k-th element) and doesn't account for group proportions.",
          "1": "Convenience sampling is based on ease of access and lacks representativeness.",
          "2": "Correct. This explicitly addresses the need to reflect subpopulation proportions.",
          "3": "Simple random sampling might miss smaller subgroups by chance, whereas stratified sampling guarantees their inclusion."
        }
      },
      {
        "id": 3,
        "topic": "Estimators",
        "difficulty": "recall",
        "question": "What is the primary conceptual difference between 'Empirical Variance' and 'Sample Variance' as presented in the slides?",
        "options": [
          "Empirical variance uses the true population mean, while sample variance uses the empirical mean.",
          "Sample variance is an unbiased estimator because it divides by (n-1), whereas empirical variance is biased.",
          "Empirical variance is used for continuous data, while sample variance is used for discrete data.",
          "There is no difference; they are different names for the same mathematical function."
        ],
        "correct_index": 1,
        "rationale": "Slide 12 shows that the empirical variance (dividing by n) is a biased estimator of the true variance. Using (n-1) in the sample variance formula corrects this bias.",
        "distractor_analysis": {
          "0": "Both typically use the empirical (sample) mean in practice.",
          "1": "Correct. The (n-1) factor (Bessel's correction) is the key to achieving unbiasedness.",
          "2": "The distinction is about estimator bias, not the nature of the data (discrete vs. continuous).",
          "3": "The slides explicitly list them as different formulas with different expected values."
        }
      },
      {
        "id": 4,
        "topic": "Bias/Unbiased",
        "difficulty": "analysis",
        "question": "If an estimator is 'consistent,' what happens as the sample size (n) approaches infinity?",
        "options": [
          "The estimator's bias remains constant but its variance reduces to zero.",
          "The estimator will always equal the true parameter for any n > 30.",
          "The probability of the estimator deviating from the true parameter by any margin epsilon goes to zero.",
          "The estimator becomes normally distributed regardless of its original bias."
        ],
        "correct_index": 2,
        "rationale": "Slide 11 defines consistency: an estimator is consistent if the probability that the estimate differs from the true value by more than epsilon vanishes as n goes to infinity.",
        "distractor_analysis": {
          "0": "If an estimator is consistent, the bias must also vanish as n approaches infinity.",
          "1": "Consistency is a probabilistic limit, not a guarantee of exactness for a specific finite n.",
          "2": "Correct. This is the formal definition of convergence in probability for a consistent estimator.",
          "3": "This describes the Central Limit Theorem's effect on the distribution of the mean, not the general definition of consistency."
        }
      },
      {
        "id": 5,
        "topic": "Mean/Variance Sensitivity",
        "difficulty": "application",
        "question": "You are analyzing a dataset of house prices where one entry was accidentally entered as $100,000,000 instead of $1,000,000. How will this outlier most likely affect your estimators?",
        "options": [
          "The median will increase significantly, but the mean will remain stable.",
          "The mean and variance will increase significantly, while the median remains relatively stable.",
          "The correlation between house size and price will become perfectly linear.",
          "The empirical distribution function will become a smooth bell curve."
        ],
        "correct_index": 1,
        "rationale": "The mean and variance are highly sensitive to outliers because they incorporate every value's magnitude (and the square of the magnitude for variance). The median, being a rank-based measure, is robust to extreme outliers.",
        "distractor_analysis": {
          "0": "This is the reverse of reality; the mean is sensitive, the median is robust.",
          "1": "Correct. Outliers 'pull' the mean and drastically inflate variance.",
          "2": "One outlier usually degrades correlation or creates a 'leverage point' rather than making it perfectly linear.",
          "3": "Outliers create heavy tails or 'jumps' in the EDF, not a smooth normal distribution."
        }
      },
      {
        "id": 6,
        "topic": "Correlation",
        "difficulty": "analysis",
        "question": "If the correlation between two random variables X and Y is zero, what can we definitively conclude about their relationship?",
        "options": [
          "X and Y are independent.",
          "There is no linear relationship between X and Y.",
          "X and Y have no relationship of any kind.",
          "The covariance between X and Y must be positive."
        ],
        "correct_index": 1,
        "rationale": "Slide 8 notes that correlation measures linear dependency. A correlation of zero only implies the absence of a linear relationship; the variables could still be non-linearly dependent.",
        "distractor_analysis": {
          "0": "Independence implies zero correlation, but zero correlation does not necessarily imply independence.",
          "1": "Correct. Correlation is specifically a measure of linear association.",
          "2": "They could have a strong non-linear relationship (e.g., Y = X^2).",
          "3": "If correlation is zero, covariance must also be zero (Correlation = Cov / (Sx*Sy))."
        }
      },
      {
        "id": 7,
        "topic": "Law of Large Numbers",
        "difficulty": "analysis",
        "question": "How does the Law of Large Numbers (LLN) justify the use of larger datasets in Data Science?",
        "options": [
          "It guarantees that larger datasets will have a smaller standard deviation than smaller ones.",
          "It ensures that the sample average will converge to the true population expected value as the dataset grows.",
          "It proves that as n increases, the data will naturally follow a Normal distribution.",
          "It states that the error of an estimator will be zero once the sample size exceeds 1,000."
        ],
        "correct_index": 1,
        "rationale": "As per Slide 13, the LLN (both Weak and Strong) describes how the sample average approaches the population mean as the number of trials or observations increases.",
        "distractor_analysis": {
          "0": "LLN is about the mean converging, not the population standard deviation shrinking.",
          "1": "Correct. This is the foundational logic for why 'more data is better' for estimation.",
          "2": "This is the Central Limit Theorem, not the Law of Large Numbers.",
          "3": "LLN describes a limit as n goes to infinity; error doesn't hit zero at a specific finite number like 1,000."
        }
      },
      {
        "id": 8,
        "topic": "Skewness",
        "difficulty": "application",
        "question": "In a 'Positive Skew' (Right Skew) distribution, such as the yearly income example on Slide 16, what is the typical relationship between the mean and the median?",
        "options": [
          "The mean is significantly lower than the median.",
          "The mean and median are identical.",
          "The mean is significantly higher than the median.",
          "The relationship between mean and median cannot be determined by skewness."
        ],
        "correct_index": 2,
        "rationale": "In a right-skewed distribution, the long tail on the right side (high values) pulls the mean upward more than it affects the median.",
        "distractor_analysis": {
          "0": "This describes a negative (left) skew.",
          "1": "This describes a perfectly symmetric distribution, like a Normal distribution.",
          "2": "Correct. High outliers in the tail increase the mean while the median remains at the 50th percentile.",
          "3": "Skewness is defined by the relative positions of the mean, median, and mode."
        }
      },
      {
        "id": 9,
        "topic": "Central Limit Theorem",
        "difficulty": "recall",
        "question": "According to the Central Limit Theorem (CLT), what specific entity becomes 'approximately normally distributed' as n becomes large?",
        "options": [
          "The underlying population data itself.",
          "The distribution of the individual samples.",
          "The distribution of the sample mean (or sum).",
          "The variance of the sample."
        ],
        "correct_index": 2,
        "rationale": "Slide 19 states that the cdf of the sum (Z) or the mean of i.i.d. variables converges to the cdf of a normal distribution. The theorem applies to the estimator (mean), not the raw data.",
        "distractor_analysis": {
          "0": "The population distribution remains whatever it originally was (e.g., uniform, exponential).",
          "1": "Individual samples follow the population distribution.",
          "2": "Correct. The *sampling distribution of the mean* is what becomes normal.",
          "3": "The sample variance does not become normally distributed through the CLT (it follows a Chi-square related distribution)."
        }
      },
      {
        "id": 10,
        "topic": "Hypothesis Testing",
        "difficulty": "analysis",
        "question": "When we 'retain' the null hypothesis (H0), what have we actually concluded?",
        "options": [
          "We have proven that H0 is definitively true.",
          "The counter-hypothesis H1 has been proven false.",
          "There is insufficient statistical evidence to reject H0 at the chosen significance level.",
          "The p-value was exactly zero."
        ],
        "correct_index": 2,
        "rationale": "Slide 22 notes the goal is 'falsification'. If we fail to reject (retain) H0, it doesn't mean H0 is true; it just means the data didn't provide enough evidence to suggest otherwise.",
        "distractor_analysis": {
          "0": "Statistics cannot 'prove' a null hypothesis; we only fail to reject it.",
          "1": "Failure to reject H0 does not equate to a proof of H1's falsehood.",
          "2": "Correct. Retaining H0 is a statement about the strength of evidence, not the absolute truth of the hypothesis.",
          "3": "A p-value of zero would lead to a strong rejection of H0, not retention."
        }
      },
      {
        "id": 11,
        "topic": "p-value",
        "difficulty": "recall",
        "question": "Based on Slide 26, how is the p-value defined in the context of hypothesis testing?",
        "options": [
          "The probability that the null hypothesis is true.",
          "The probability that the counter-hypothesis is true.",
          "The minimal significance level at which the null hypothesis can be rejected.",
          "The confidence level (1 - alpha) of the test."
        ],
        "correct_index": 2,
        "rationale": "The slide explicitly defines the p-value as the 'minimal significance level at which H0 can be rejected' based on the observed data.",
        "distractor_analysis": {
          "0": "This is a common misconception; the p-value is a conditional probability of the data, not the hypothesis.",
          "1": "p-values are calculated assuming the null is true; they don't measure the truth of the alternative.",
          "2": "Correct. This is the technical definition provided in the slide deck.",
          "3": "The p-value is compared against the significance level (alpha), but it is not the same as the confidence level."
        }
      },
      {
        "id": 12,
        "topic": "One/Two sided tests",
        "difficulty": "application",
        "question": "You are testing a new drug and you only want to reject the null hypothesis if the drug is *better* than the current standard. Which type of test should you use?",
        "options": [
          "A two-sided test",
          "A one-sided test",
          "A Chi-Square independence test",
          "A Wald test for variance"
        ],
        "correct_index": 1,
        "rationale": "Slide 25 explains that a test where H1 specifies a direction (e.g., mean > theta_0) is a one-sided test. Since we only care if it is 'better', not just 'different', the one-sided test is appropriate.",
        "distractor_analysis": {
          "0": "A two-sided test looks for any difference (better or worse).",
          "1": "Correct. Directional hypotheses require one-sided tests.",
          "2": "Chi-Square tests are typically for goodness-of-fit or independence, not comparing means for directional improvement.",
          "3": "We are testing the mean (efficacy), not the variance."
        }
      },
      {
        "id": 13,
        "topic": "Mean Squared Error",
        "difficulty": "analysis",
        "question": "According to the MSE decomposition (Slide 15), if an estimator is unbiased, what constitutes its Mean Squared Error?",
        "options": [
          "The MSE is equal to the Bias squared.",
          "The MSE is equal to the Variance of the estimator.",
          "The MSE is equal to the sum of the Sample Mean and the Sample Variance.",
          "The MSE is zero."
        ],
        "correct_index": 1,
        "rationale": "Slide 15 shows: MSE = Var + Bias^2. If the estimator is unbiased, Bias = 0, therefore MSE = Var.",
        "distractor_analysis": {
          "0": "This would only be true if Variance was zero.",
          "1": "Correct. For unbiased estimators, the error is purely due to variance.",
          "2": "The decomposition involves Var and Bias^2, not the raw mean and variance values.",
          "3": "MSE is only zero if both bias and variance are zero, which is almost never true for a random sample."
        }
      },
      {
        "id": 14,
        "topic": "Normal Distribution",
        "difficulty": "recall",
        "question": "For a standard normal distribution N(0,1), what percentage of the data roughly falls within one standard deviation ([-1, 1]) of the mean?",
        "options": [
          "50%",
          "95%",
          "68.2%",
          "99.7%"
        ],
        "correct_index": 2,
        "rationale": "Slide 18 shows the bell curve. The area between -1 sigma and +1 sigma is 34.1% + 34.1% = 68.2%.",
        "distractor_analysis": {
          "0": "This is the area to one side of the mean.",
          "1": "This is the area within roughly 2 standard deviations.",
          "2": "Correct. This is a fundamental property of the Normal distribution shown in the graphic.",
          "3": "This is the area within 3 standard deviations."
        }
      },
      {
        "id": 15,
        "topic": "Central Limit Theorem",
        "difficulty": "analysis",
        "question": "What happens to the 'bell shape' of the sample mean distribution as the sample size n increases from 2 to 100?",
        "options": [
          "It becomes wider and flatter.",
          "It becomes increasingly narrower and more 'peaked' around the true mean.",
          "It stays exactly the same shape regardless of n.",
          "It shifts further to the right on the x-axis."
        ],
        "correct_index": 1,
        "rationale": "As n increases, the standard error (sigma/sqrt(n)) decreases. This means the distribution of the mean becomes more concentrated (narrower) around the population mean.",
        "distractor_analysis": {
          "0": "This would happen if n decreased or variance increased.",
          "1": "Correct. Larger n leads to higher precision (lower variance of the mean).",
          "2": "The CLT says it becomes more *Normal* in shape, but the *Corollary* on Slide 19 shows the variance is sigma^2/n, which changes with n.",
          "3": "The distribution is centered at the population mean 'mu', which does not change with n."
        }
      },
      {
        "id": 16,
        "topic": "Covariance",
        "difficulty": "application",
        "question": "If you calculate a 'Sample Covariance' and get a large positive value, what does this tell you qualitatively about the two variables?",
        "options": [
          "As one variable increases, the other tends to increase.",
          "The two variables are identical.",
          "One variable causes the other to change.",
          "The variables have a very low standard deviation."
        ],
        "correct_index": 0,
        "rationale": "Positive covariance indicates that the variables move in the same direction. It does not imply identity or causation.",
        "distractor_analysis": {
          "0": "Correct. This is the qualitative definition of positive covariance.",
          "1": "Identity would imply a specific correlation and variance relationship, not just positive covariance.",
          "2": "Covariance measures association, not causation.",
          "3": "A large covariance often implies large standard deviations in the underlying variables."
        }
      },
      {
        "id": 17,
        "topic": "Confidence Intervals",
        "difficulty": "analysis",
        "question": "If you decrease the significance level (alpha) from 0.05 to 0.01, what happens to the width of the resulting confidence interval?",
        "options": [
          "The interval becomes narrower.",
          "The interval becomes wider.",
          "The interval stays the same.",
          "The interval disappears."
        ],
        "correct_index": 1,
        "rationale": "Decreasing alpha means increasing the confidence level (1-alpha) from 95% to 99%. To be more confident that the interval contains the true parameter, the interval must be wider.",
        "distractor_analysis": {
          "0": "Narrower intervals correspond to *higher* alpha (less confidence).",
          "1": "Correct. More certainty (lower alpha) requires a larger 'net' (wider interval).",
          "2": "The critical value Z or t increases as alpha decreases, changing the width.",
          "3": "The interval only disappears if the sample size were infinite and variance zero."
        }
      },
      {
        "id": 18,
        "topic": "Empirical Median",
        "difficulty": "application",
        "question": "Why is the empirical median preferred over the empirical mean when reporting 'Typical Household Income' in a country with high wealth inequality?",
        "options": [
          "The median is easier to calculate mathematically.",
          "The mean is biased by a few very high earners, making the 'typical' person seem richer than they are.",
          "The median is always higher than the mean in income distributions.",
          "The Law of Large Numbers only applies to the median."
        ],
        "correct_index": 1,
        "rationale": "Slide 16 explains this exact scenario. High outliers (millionaires) pull the mean up significantly, while the median remains a better representation of the middle of the population.",
        "distractor_analysis": {
          "0": "Ease of calculation is not the reason; statistical representativeness is.",
          "1": "Correct. This is the 'usefulness' argument from the slides.",
          "2": "In right-skewed distributions like income, the mean is actually higher than the median.",
          "3": "The LLN primarily concerns the convergence of the sample average (mean)."
        }
      },
      {
        "id": 19,
        "topic": "Law of Large Numbers",
        "difficulty": "analysis",
        "question": "In the coin flip example on Slide 13, why does flipping a coin 2000 times give a 'better' mean than flipping it 5 times?",
        "options": [
          "Because 2000 is a lucky number in statistics.",
          "The probability of heads changes as you flip more often.",
          "The variance of the sample average decreases as n increases, making the estimate more stable.",
          "The Strong Law of Large Numbers only activates after 1000 trials."
        ],
        "correct_index": 2,
        "rationale": "According to the LLN, the sample average converges to the expected value. The variance of this average is sigma^2/n, so a larger n (2000 vs 5) significantly reduces the fluctuation around the true mean.",
        "distractor_analysis": {
          "0": "Statistics relies on mathematical proof, not luck.",
          "1": "The underlying probability 'p' is constant for i.i.d. trials.",
          "2": "Correct. Increased sample size leads to a more 'stable' and accurate average.",
          "3": "LLN applies to any n, but the convergence is 'closer' as n grows; there is no 'activation' threshold."
        }
      },
      {
        "id": 20,
        "topic": "Hypothesis Testing",
        "difficulty": "recall",
        "question": "What is the 'null hypothesis' (H0) generally formulated to be?",
        "options": [
          "The most complex explanation for the data.",
          "The claim that the researcher is trying to prove is true.",
          "A statement of 'no effect' or the simplest possible assumption.",
          "A statement that the sample variance is zero."
        ],
        "correct_index": 2,
        "rationale": "Slide 27 describes the 'General recipe': formulate the null hypothesis as the 'simplest hypothesis'. It usually represents the status quo or 'no difference'.",
        "distractor_analysis": {
          "0": "We aim for parsimony; the null is the simplest state.",
          "1": "The researcher usually wants to *reject* the null in favor of the alternative (H1).",
          "2": "Correct. This is the standard statistical convention.",
          "3": "Variance is almost never zero; H0 is about population parameters, not making variance disappear."
        }
      },
      {
        "id": 21,
        "topic": "Bias/Unbiased",
        "difficulty": "analysis",
        "question": "If you use the 'Empirical Variance' formula (dividing by n) on a small sample of 5 people's heights, how will your estimate likely relate to the true population variance?",
        "options": [
          "It will be exactly correct.",
          "It will tend to underestimate the true variance.",
          "It will tend to overestimate the true variance.",
          "It will be unbiased but inconsistent."
        ],
        "correct_index": 1,
        "rationale": "Slide 12 shows E(S_em^2) = [(n-1)/n] * Var(X). Since (n-1)/n is less than 1, the empirical variance systematically underestimates the true variance (it is biased downward).",
        "distractor_analysis": {
          "0": "Estimators on small samples are rarely 'exactly' correct due to sampling error and bias.",
          "1": "Correct. This is why we use (n-1) to 'inflate' the estimate slightly to reach unbiasedness.",
          "2": "Dividing by n makes the denominator larger, which makes the result smaller (underestimation).",
          "3": "It is both biased and consistent (as n goes to infinity, (n-1)/n goes to 1)."
        }
      },
      {
        "id": 22,
        "topic": "Estimators",
        "difficulty": "recall",
        "question": "What does it mean for an estimator to be 'Asymptotically Normal' (as mentioned for MLE on Slide 17)?",
        "options": [
          "The estimator is only accurate if the original data was normal.",
          "As the sample size increases, the distribution of the estimator approaches a normal distribution.",
          "The estimator's value eventually becomes zero.",
          "The estimator can only be used on data from Wikipedia."
        ],
        "correct_index": 1,
        "rationale": "Asymptotic normality means that for large n, the sampling distribution of the estimator (like the Maximum Likelihood Estimator) behaves like a normal distribution, regardless of the population distribution.",
        "distractor_analysis": {
          "0": "Asymptotic normality is a property of the estimator's distribution, not the data's.",
          "1": "Correct. This property allows us to use Z-tables for testing even with non-normal data if n is large.",
          "2": "Normality refers to the shape, not a value of zero.",
          "3": "Wikipedia was just the source for the images, not a constraint on the math."
        }
      },
      {
        "id": 23,
        "topic": "p-value",
        "difficulty": "application",
        "question": "A p-value of 0.03 is calculated for a test. If your significance level (alpha) was set at 0.05, what is your conclusion?",
        "options": [
          "Reject the null hypothesis; the result is statistically significant.",
          "Retain the null hypothesis; the result is not significant.",
          "Increase the sample size until the p-value reaches 0.01.",
          "The test is invalid because the p-value must be lower than 0.01."
        ],
        "correct_index": 0,
        "rationale": "If p-value < alpha, we reject the null hypothesis. Since 0.03 < 0.05, the result is significant.",
        "distractor_analysis": {
          "0": "Correct. The evidence is strong enough to reject H0 at the 5% level.",
          "1": "We only retain if p-value > alpha.",
          "2": "'P-hacking' (increasing n just to change the p-value) is an unethical/incorrect practice.",
          "3": "The threshold (alpha) is chosen by the researcher; 0.05 is the most common standard."
        }
      },
      {
        "id": 24,
        "topic": "Skewness",
        "difficulty": "analysis",
        "question": "Looking at the 'Empirical Skew' formula on Slide 17, what is the effect of the cubed term (xi - mean)^3 in the numerator?",
        "options": [
          "It ensures the skewness value is always positive.",
          "It preserves the sign of the deviations, allowing us to see if the tail is on the left or right.",
          "It eliminates the effect of outliers.",
          "It makes the formula identical to the variance formula."
        ],
        "correct_index": 1,
        "rationale": "Cubing a negative number stays negative; cubing a positive stays positive. This allows the formula to indicate direction (negative for left-skew, positive for right-skew).",
        "distractor_analysis": {
          "0": "Squaring (like in variance) makes values positive; cubing does not.",
          "1": "Correct. This is why the third moment is used for skewness.",
          "2": "Cubing actually *magnifies* the effect of outliers.",
          "3": "Variance uses a squared term (second moment), not a cubed term."
        }
      },
      {
        "id": 25,
        "topic": "Central Limit Theorem",
        "difficulty": "application",
        "question": "You have a Galton Machine (Slide 21). Each ball's path is a sequence of i.i.d. Bernoulli choices. Why do the balls form a bell curve at the bottom?",
        "options": [
          "Because the machine is tilted.",
          "The sum of many independent random movements converges to a normal distribution.",
          "The balls are attracted to the center by gravity.",
          "The Law of Large Numbers forces every ball to land in the center bin."
        ],
        "correct_index": 1,
        "rationale": "The Galton Machine is a physical demonstration of the CLT. The final position of a ball is the sum of many independent 'left/right' steps, leading to a normal distribution of final positions.",
        "distractor_analysis": {
          "0": "Tilting would just shift the mean, not create the bell shape.",
          "1": "Correct. This is the CLT in action.",
          "2": "Gravity pulls them down, but the horizontal 'spread' is defined by probability, not gravitational attraction to a point.",
          "3": "LLN says the *average* of all balls will be at the center; CLT explains the *shape* of the entire pile."
        }
      },
      {
        "id": 26,
        "topic": "t-Test",
        "difficulty": "analysis",
        "question": "Why would a researcher use a t-test instead of a Z-test (Slide 33)?",
        "options": [
          "The sample size is extremely large (n > 10,000).",
          "The population variance is unknown and must be estimated from the sample.",
          "The data is categorical rather than numerical.",
          "The t-test is only used for one-sided hypotheses."
        ],
        "correct_index": 1,
        "rationale": "Slide 33 states the t-test is for 'unknown mean and unknown variance'. When we estimate variance from the sample (s^2), the distribution of the mean follows a Student's t-distribution rather than a normal Z-distribution.",
        "distractor_analysis": {
          "0": "For very large n, the t-distribution becomes nearly identical to the Z-distribution.",
          "1": "Correct. Estimating variance adds uncertainty, which the t-distribution accounts for with its 'heavier tails'.",
          "2": "Both tests are for numerical means.",
          "3": "Both Z and t tests can be one or two-sided."
        }
      },
      {
        "id": 27,
        "topic": "Correlation",
        "difficulty": "application",
        "question": "Slide 8 mentions that correlation (r) is 1 if Y = aX + b and a > 0. What does r = -1 imply?",
        "options": [
          "There is no relationship between X and Y.",
          "There is a perfect linear relationship where Y decreases as X increases.",
          "The variables have different units.",
          "The variance of Y is negative."
        ],
        "correct_index": 1,
        "rationale": "A correlation of -1 indicates a perfect negative linear relationship. As one variable goes up, the other goes down in a perfectly straight line.",
        "distractor_analysis": {
          "0": "That would be r = 0.",
          "1": "Correct. The sign of the correlation indicates the direction of the slope.",
          "2": "Correlation is dimensionless; units don't affect its value.",
          "3": "Variance is always non-negative by definition."
        }
      },
      {
        "id": 28,
        "topic": "Bias/Unbiased",
        "difficulty": "analysis",
        "question": "Which of the following is considered the 'Best Estimator' for the true mean of many useful distributions (Slide 14)?",
        "options": [
          "The Empirical Median",
          "The Sample Mean",
          "The Maximum value in the sample",
          "The Sample Variance"
        ],
        "correct_index": 1,
        "rationale": "Slide 14 explicitly notes that the 'sample mean is the best estimator of the true mean for many useful distributions' because it is unbiased and has the lowest variance among unbiased estimators (in many cases).",
        "distractor_analysis": {
          "0": "Median is robust but often has higher variance than the mean for normal-like distributions.",
          "1": "Correct. It is the Minimum Variance Unbiased Estimator (MVUE) for many cases.",
          "2": "The maximum is a highly biased estimator of the mean.",
          "3": "Variance is an estimator of spread, not the mean (location)."
        }
      },
      {
        "id": 29,
        "topic": "Chi-Square",
        "difficulty": "recall",
        "question": "What is the primary purpose of a Chi-Square Goodness-of-Fit test (Slide 35)?",
        "options": [
          "To see if a sample follows a proposed discrete distribution.",
          "To determine the correlation between two continuous variables.",
          "To estimate the mean of a normal distribution with unknown variance.",
          "To prove that two variables are independent."
        ],
        "correct_index": 0,
        "rationale": "As per Slide 35, the test checks if the observed frequencies 'follow a proposed discrete distribution'.",
        "distractor_analysis": {
          "0": "Correct. It compares observed vs. expected frequencies.",
          "1": "Correlation is measured by 'r' (Pearson), not Chi-square.",
          "2": "That is the role of the t-test.",
          "3": "Chi-Square can be used to *test* independence (Slide 37), but you can't 'prove' it, only fail to reject the null of independence."
        }
      },
      {
        "id": 30,
        "topic": "Sampling",
        "difficulty": "analysis",
        "question": "Why is 'Systematic Sampling' (Slide 6) marked as 'biased' in some contexts?",
        "options": [
          "It requires a computer to pick the elements.",
          "If the underlying list has a periodic pattern that matches the sampling interval 'k', it can produce a non-representative sample.",
          "It always results in the same mean as convenience sampling.",
          "It only works for populations smaller than 100."
        ],
        "correct_index": 1,
        "rationale": "If a population list is ordered in a way that repeats every k elements (e.g., every 10th person is a manager), picking every 10th person will result in a sample of only managers, which is highly biased.",
        "distractor_analysis": {
          "0": "Using a computer doesn't cause bias.",
          "1": "Correct. Periodicity in the data is the main risk for systematic sampling.",
          "2": "Systematic is usually much better than convenience, but less robust than pure random sampling.",
          "3": "Sampling methods work for any population size; the constraints are about logic, not size."
        }
      },
      {
        "id": 31,
        "topic": "Hypothesis Testing",
        "difficulty": "application",
        "question": "If your test statistic falls inside the 'Critical Region' (Slide 24), what is the appropriate action?",
        "options": [
          "Retain the null hypothesis.",
          "Reject the null hypothesis.",
          "Change the significance level until it falls outside.",
          "Discard the data as an outlier."
        ],
        "correct_index": 1,
        "rationale": "The critical region is the set of values for which the null hypothesis is rejected. If the statistic is in this region, it means the result is unlikely to have occurred by chance under H0.",
        "distractor_analysis": {
          "0": "We retain if it is *outside* the critical region.",
          "1": "Correct. This is the definition of the critical region.",
          "2": "This is unethical and invalidates the statistical process.",
          "3": "The entire point of the test is to see where the data falls; discarding it defeats the purpose."
        }
      },
      {
        "id": 32,
        "topic": "p-value",
        "difficulty": "analysis",
        "question": "Which of the following would lead to a *smaller* p-value, assuming all else remains constant?",
        "options": [
          "A smaller sample size.",
          "A larger difference between the observed sample mean and the null hypothesis mean.",
          "A larger sample variance.",
          "A higher significance level alpha."
        ],
        "correct_index": 1,
        "rationale": "The p-value measures how 'extreme' the data is relative to the null. A larger gap between the observation and the null expectation is more extreme, leading to a smaller p-value.",
        "distractor_analysis": {
          "0": "Smaller samples have more uncertainty, leading to *larger* p-values (harder to reject).",
          "1": "Correct. More 'extreme' data = lower p-value.",
          "2": "More noise (variance) makes the result less certain, leading to a larger p-value.",
          "3": "Alpha is a threshold we choose; it doesn't change the p-value itself (which is calculated from the data)."
        }
      },
      {
        "id": 33,
        "topic": "Estimators",
        "difficulty": "recall",
        "question": "According to Slide 11, what is 'Bias' in the context of an estimator theta-hat?",
        "options": [
          "The difference between the expected value of the estimator and the true parameter.",
          "The spread of the estimator's values.",
          "The mistake made by the researcher in collecting data.",
          "The ratio of the sample mean to the population mean."
        ],
        "correct_index": 0,
        "rationale": "Slide 11 defines an unbiased estimator as one where E(theta-hat) = theta. Bias is the difference between these two values.",
        "distractor_analysis": {
          "0": "Correct. It measures if the estimator is 'on target' on average.",
          "1": "The spread is the 'Variance', not the Bias.",
          "2": "Bias is a statistical property of the formula, not just human error.",
          "3": "Bias is an additive difference, not a ratio."
        }
      },
      {
        "id": 34,
        "topic": "One/Two sided tests",
        "difficulty": "analysis",
        "question": "What is a disadvantage of using a two-sided test when you have a specific directional hypothesis?",
        "options": [
          "It is more likely to give a false positive (Type I error).",
          "It requires more data to calculate.",
          "It is 'harder' to reject the null because the significance level alpha is split between two tails.",
          "It cannot be used with the t-distribution."
        ],
        "correct_index": 2,
        "rationale": "In a two-sided test, alpha is divided (e.g., 0.025 in each tail). This means you need a more extreme result in one specific direction to reject the null compared to a one-sided test where the full 0.05 is in one tail.",
        "distractor_analysis": {
          "0": "A two-sided test is actually more conservative (less likely to have a false positive in one specific direction).",
          "1": "Data requirements are the same; the difference is in the critical values used.",
          "2": "Correct. You sacrifice 'power' in one direction to check for both.",
          "3": "t-distributions are used for both one and two-sided tests."
        }
      },
      {
        "id": 35,
        "topic": "Standard Error",
        "difficulty": "recall",
        "question": "How is 'Standard Error' related to 'Standard Deviation' (Slide 30)?",
        "options": [
          "They are the same thing.",
          "Standard error is the standard deviation of the population.",
          "Standard error is the standard deviation of an estimator (like the mean).",
          "Standard error is the square of the standard deviation."
        ],
        "correct_index": 2,
        "rationale": "Slide 30 defines s = sqrt(Var(theta-hat)) as the 'standard error'. It represents the typical distance an estimate falls from the true parameter.",
        "distractor_analysis": {
          "0": "Standard deviation usually refers to raw data; standard error refers to the estimate.",
          "1": "No, that is 'sigma'.",
          "2": "Correct. It is the 'SD' of the sampling distribution.",
          "3": "The square of SD is Variance."
        }
      },
      {
        "id": 36,
        "topic": "Hypothesis Testing",
        "difficulty": "application",
        "question": "You conduct an IQ test on students (Slide 23). H0 is mean=100. Your sample mean is 115. If the p-value is 0.001, what is the best qualitative interpretation?",
        "options": [
          "The students are definitely geniuses.",
          "A sample mean of 115 is extremely unlikely to occur if the true population mean were really 100.",
          "The test was biased because 115 is too far from 100.",
          "The students' IQs are exactly 115 on average."
        ],
        "correct_index": 1,
        "rationale": "A very low p-value (0.001) means that the observed data is highly inconsistent with the null hypothesis. It suggests we should reject the idea that the true mean is 100.",
        "distractor_analysis": {
          "0": "Statistics suggests a difference, but 'genius' is a subjective label not proven by one test.",
          "1": "Correct. This is the definition of a small p-value: the data is rare under the null.",
          "2": "A large difference isn't bias; it's 'evidence' for a real effect.",
          "3": "115 is the *sample* mean; the population mean could be 112, 118, etc."
        }
      },
      {
        "id": 37,
        "topic": "Consistency",
        "difficulty": "analysis",
        "question": "Slide 12 states that Empirical Variance is a 'biased consistent' estimator. Why is it still useful despite the bias?",
        "options": [
          "Because the bias is zero when n=1.",
          "Because as the dataset becomes very large (n -> infinity), the bias disappears.",
          "Because biased estimators have lower variance than unbiased ones.",
          "Because 'biased' in statistics means it is more fair."
        ],
        "correct_index": 1,
        "rationale": "Consistency means the estimator converges to the true value as n grows. Even if it is biased for small n, the bias (n-1)/n becomes negligible as n increases (e.g., 999,999/1,000,000).",
        "distractor_analysis": {
          "0": "The bias is actually infinite or undefined for n=1 (division by zero in sample variance).",
          "1": "Correct. In 'Big Data' contexts, the difference between n and n-1 is irrelevant.",
          "2": "While some biased estimators have lower variance (Bias-Variance trade-off), that is not the definition of why a *consistent* estimator is useful.",
          "3": "In statistics, 'bias' is a mathematical term for 'off-center', not a social term for 'fairness'."
        }
      },
      {
        "id": 38,
        "topic": "Central Limit Theorem",
        "difficulty": "analysis",
        "question": "Why is the Central Limit Theorem considered a 'bridge' between different types of data distributions and the Normal distribution?",
        "options": [
          "It says that all data eventually becomes Normal if you wait long enough.",
          "It allows us to use Normal-based tests (like Z-tests) on the mean of *any* distribution, provided the sample size is large.",
          "It turns discrete data into continuous data.",
          "It proves that the population mean is always zero."
        ],
        "correct_index": 1,
        "rationale": "The CLT's power is that it doesn't matter what the 'underlying' distribution is (Uniform, Binomial, etc.); the *average* will behave normally. This is why we can use the same tests for income, height, or error rates.",
        "distractor_analysis": {
          "0": "The data doesn't change; only the *average* of the data follows the bell curve.",
          "1": "Correct. This is why the Normal distribution is 'Universal' in statistics.",
          "2": "The mean of discrete data is often a continuous-looking distribution, but that's not the 'bridge' CLT provides.",
          "3": "The mean is 'mu', which can be any finite value."
        }
      },
      {
        "id": 39,
        "topic": "Correlation",
        "difficulty": "recall",
        "question": "According to Slide 8, what happens if you turn on a car where the engine is broken and the fuel tank is empty?",
        "options": [
          "They become independent.",
          "They gain a conditional dependence.",
          "The correlation becomes exactly 1.",
          "The variance of the fuel levels increases."
        ],
        "correct_index": 1,
        "rationale": "The slide uses this as an example of conditional dependence: variables can be independent normally but become dependent given a third variable (the car's failure to start).",
        "distractor_analysis": {
          "0": "The example states they were independent *before* the third variable was introduced.",
          "1": "Correct. This highlights that independence can change based on context/evidence.",
          "2": "Dependency doesn't mean *perfect linear* dependency (correlation 1).",
          "3": "Fuel level variance is irrelevant to the logical point of dependency."
        }
      },
      {
        "id": 40,
        "topic": "Mean/Variance Sensitivity",
        "difficulty": "analysis",
        "question": "You have a sample [10, 12, 11, 13, 11]. You add a new data point: 500. Which estimator will change the most in proportion to its original value?",
        "options": [
          "The Empirical Median",
          "The Empirical Mean",
          "The Sample Variance",
          "The Sample Skewness"
        ],
        "correct_index": 2,
        "rationale": "The variance involves the *square* of the distance from the mean. Since the new point is very far away, its contribution to the variance ( (500-mean)^2 ) will be enormous compared to its contribution to the mean.",
        "distractor_analysis": {
          "0": "The median will barely change (it might shift from 11 to 11.5 or 12).",
          "1": "The mean will increase, but not as drastically as variance which squares the outlier's distance.",
          "2": "Correct. Variance is extremely sensitive to large outliers due to the squaring term.",
          "3": "Skewness would also change significantly, but variance is the fundamental measure of spread that 'explodes' with such an outlier."
        }
      },
      {
        "id": 41,
        "topic": "Law of Large Numbers",
        "difficulty": "application",
        "question": "A casino relies on the Law of Large Numbers to ensure profit. How does this work?",
        "options": [
          "They ensure every individual player wins at least once.",
          "Over thousands of bets, the average payout to players will converge to the expected value, which is slightly less than the bet amount.",
          "They use a Z-test to see if players are cheating.",
          "They only allow 30 people to play at a time to keep n small."
        ],
        "correct_index": 1,
        "rationale": "The 'House Edge' is a small difference in expected value. LLN ensures that over a large 'n' (many bets), the actual average outcome for the casino will be very close to that theoretical expected profit.",
        "distractor_analysis": {
          "0": "LLN doesn't guarantee individual outcomes.",
          "1": "Correct. This is the 'stability' that LLN provides for large datasets.",
          "2": "Cheating detection is a different application; the core business model is based on LLN.",
          "3": "Small n would increase the casino's risk (variance); they want n as large as possible."
        }
      },
      {
        "id": 42,
        "topic": "Normal Distribution",
        "difficulty": "analysis",
        "question": "In the 'Standard Normal Distribution' formula (Slide 18), what is the effect of the term 'sigma' in the denominator of the exponent?",
        "options": [
          "It shifts the distribution left or right.",
          "It determines the height of the curve at the mean.",
          "It scales the horizontal 'spread' of the distribution.",
          "It ensures the area under the curve is always zero."
        ],
        "correct_index": 2,
        "rationale": "The sigma (standard deviation) acts as a scaling factor. A larger sigma spreads the curve out horizontally, while a smaller sigma squeezes it toward the mean.",
        "distractor_analysis": {
          "0": "That is 'mu' (the mean).",
          "1": "The height is determined by 1/(sigma*sqrt(2pi)), but the primary 'shape' role of sigma is spread.",
          "2": "Correct. Sigma measures dispersion.",
          "3": "The area under a probability distribution must always be 1, not 0."
        }
      },
      {
        "id": 43,
        "topic": "Hypothesis Testing",
        "difficulty": "analysis",
        "question": "If you reject a null hypothesis at alpha=0.05, will you also necessarily reject it at alpha=0.01?",
        "options": [
          "Yes, because 0.01 is more strict.",
          "No, because the p-value might be between 0.01 and 0.05.",
          "Yes, because the p-value doesn't change.",
          "It depends on whether the test was one-sided or two-sided."
        ],
        "correct_index": 1,
        "rationale": "Rejecting at 0.05 means p < 0.05. However, if the p-value is 0.03, it is smaller than 0.05 (reject) but larger than 0.01 (retain).",
        "distractor_analysis": {
          "0": "Being more strict means it's *harder* to reject; therefore, you might not.",
          "1": "Correct. A result can be 'significant' at one level but not a stricter one.",
          "2": "The p-value doesn't change, but the conclusion depends on the alpha it is compared against.",
          "3": "While test type affects p-value, the logic of alpha thresholds applies the same way to any p-value."
        }
      },
      {
        "id": 44,
        "topic": "Chi-Square",
        "difficulty": "application",
        "question": "You want to know if there is a relationship between 'Gender' and 'Preference for Coffee vs Tea'. Which test from the Appendix should you use?",
        "options": [
          "Wald Test",
          "t-Test for unknown variance",
          "Chi-Square independence test",
          "Empirical Skewness test"
        ],
        "correct_index": 2,
        "rationale": "Gender and Coffee/Tea preference are categorical variables. Slide 37 shows the 'Chi-Square independence test' is used for testing relationships between features in a contingency table.",
        "distractor_analysis": {
          "0": "Wald test is generally for comparing a parameter to a fixed value.",
          "1": "t-tests are for numerical means, not categorical associations.",
          "2": "Correct. This is the standard test for 'association' between categories.",
          "3": "Skewness is for the shape of a single numerical distribution."
        }
      },
      {
        "id": 45,
        "topic": "Estimators",
        "difficulty": "recall",
        "question": "What is 'Maximum Likelihood Estimation' (MLE) primarily trying to do?",
        "options": [
          "Find the parameter values that make the observed data most probable.",
          "Minimize the variance of the sample.",
          "Ensure the data follows a Normal distribution.",
          "Calculate the median of a large dataset."
        ],
        "correct_index": 0,
        "rationale": "MLE (Slide 17) is an estimator that 'maximizes the likelihood' (probability) of the observed sample given the parameters.",
        "distractor_analysis": {
          "0": "Correct. It is a fundamental method for parameter estimation.",
          "1": "MLE doesn't minimize sample variance; it finds parameters for a distribution.",
          "2": "MLE can be used for any distribution (Poisson, Binomial, etc.), not just Normal.",
          "3": "MLE is a general technique, whereas median is a specific estimator."
        }
      },
      {
        "id": 46,
        "topic": "p-value",
        "difficulty": "analysis",
        "question": "A researcher states, 'My p-value is 0.04, so there is a 4% chance the null hypothesis is true.' What is wrong with this statement?",
        "options": [
          "The p-value should be multiplied by 100.",
          "The p-value measures the probability of the data given the null, not the probability of the null itself.",
          "A p-value of 0.04 is not significant enough to make such a claim.",
          "The null hypothesis is never a percentage."
        ],
        "correct_index": 1,
        "rationale": "This is a major misconception in statistics. The p-value is P(Data | H0), not P(H0 | Data). We cannot state the probability that the hypothesis is true using frequentist p-values.",
        "distractor_analysis": {
          "0": "0.04 is 4%, so the math isn't the issue; the logic is.",
          "1": "Correct. It's a conditional probability of observing such data if the null were true.",
          "2": "It is significant (usually), but the interpretation of 'probability of H0' is always wrong regardless of the number.",
          "3": "Hypotheses aren't percentages, but probabilities are; the error is in the 'direction' of the logic."
        }
      },
      {
        "id": 47,
        "topic": "Normal Distribution",
        "difficulty": "application",
        "question": "You have a normal distribution N(100, 16). What is the mean and the standard deviation?",
        "options": [
          "Mean = 100, SD = 16",
          "Mean = 10, SD = 4",
          "Mean = 100, SD = 4",
          "Mean = 16, SD = 100"
        ],
        "correct_index": 2,
        "rationale": "The notation N(mu, sigma^2) is standard (Slide 18). Here, mu = 100 and sigma^2 = 16, so sigma = sqrt(16) = 4.",
        "distractor_analysis": {
          "0": "This mistakes the variance for the standard deviation.",
          "1": "This takes the square root of the mean, which is incorrect.",
          "2": "Correct. 100 is the mean, and the square root of 16 is the SD.",
          "3": "This reverses the parameters."
        }
      },
      {
        "id": 48,
        "topic": "Estimators",
        "difficulty": "analysis",
        "question": "Which property of the 'Empirical Distribution Function' (EDF) is highlighted on Slide 12?",
        "options": [
          "It is only useful for small datasets.",
          "It is an unbiased and consistent estimator of the true Cumulative Distribution Function (CDF).",
          "It always follows a bell curve.",
          "It can only be used if we know the true mean."
        ],
        "correct_index": 1,
        "rationale": "Slide 12 explicitly lists the empirical distribution function as an 'unbiased consistent estimator of the true cumulative distribution F_x'.",
        "distractor_analysis": {
          "0": "EDF actually becomes more powerful and accurate as n increases.",
          "1": "Correct. It 'mimics' the true CDF perfectly in the limit.",
          "2": "The EDF's shape depends on the data (it's a step function); it doesn't force a bell curve.",
          "3": "EDF is calculated directly from the sample data points without needing parameters."
        }
      },
      {
        "id": 49,
        "topic": "Hypothesis Testing",
        "difficulty": "recall",
        "question": "In the Wald Test (Slide 30), what is 'W' approximately distributed as for large samples?",
        "options": [
          "A t-distribution with n-1 degrees of freedom.",
          "A Normal distribution N(0,1).",
          "A Chi-Square distribution.",
          "A Uniform distribution."
        ],
        "correct_index": 1,
        "rationale": "Slide 30 states: 'The test variable W := ... is approximately N(0,1)-distributed'.",
        "distractor_analysis": {
          "0": "This is for the t-test when variance is unknown and n is small.",
          "1": "Correct. Wald tests typically use the Z-table for critical values.",
          "2": "Chi-Square is for different types of tests (variance or categorical).",
          "3": "Statistical test variables are designed to follow specific shapes like Normal or t, never Uniform."
        }
      },
      {
        "id": 50,
        "topic": "Comparative Analysis",
        "difficulty": "analysis",
        "question": "Comparing the LLN and CLT: Which one explains *where* the average goes, and which one explains the *shape* of the average's distribution?",
        "options": [
          "LLN explains the shape; CLT explains the location.",
          "CLT explains the location; LLN explains the shape.",
          "LLN explains the location (convergence to the mean); CLT explains the shape (Normal distribution).",
          "Both explain the same thing; they are synonyms."
        ],
        "correct_index": 2,
        "rationale": "The Law of Large Numbers dictates that the sample mean converges to a specific point (the population mean). The Central Limit Theorem describes the fluctuating 'shape' of that mean's distribution around that point as it converges.",
        "distractor_analysis": {
          "0": "This is the opposite of their roles.",
          "1": "This is also swapped.",
          "2": "Correct. Location/Convergence = LLN. Shape/Distribution = CLT.",
          "3": "They are distinct mathematical theorems with different (though related) conclusions."
        }
      }
    ]
  },
  "foundations-03": {
    "title": "Foundations of AI - Information Theory",
    "questions": [
      {
        "id": 1,
        "topic": "Information Content",
        "difficulty": "recall",
        "question": "In information theory, how is the relationship between the probability of an event and its information content (surprise) best described?",
        "options": [
          "Information content increases as the probability of the event decreases.",
          "Information content is independent of the probability of the event.",
          "Information content increases linearly with the probability of the event.",
          "Information content only exists for events with a probability of 0.5."
        ],
        "correct_index": 0,
        "rationale": "Information content, or self-information, is defined as h(x) = -log2 P(x). This inverse relationship means rare (low probability) events carry more surprise and thus more information than common (high probability) events.",
        "distractor_analysis": {
          "0": "Correct. Low probability equals high surprise.",
          "1": "Incorrect; information is a direct function of probability in this framework.",
          "2": "Incorrect; the relationship is logarithmic and inverse, not linear.",
          "3": "Incorrect; information content is defined for all probabilities in the range (0, 1]."
        }
      },
      {
        "id": 2,
        "topic": "Entropy",
        "difficulty": "application",
        "question": "If a discrete random variable has only one possible state that occurs with probability 1.0, what is the entropy of this variable?",
        "options": [
          "Exactly 0 bits",
          "Exactly 1 bit",
          "Positive infinity",
          "It cannot be calculated because log(0) is undefined."
        ],
        "correct_index": 0,
        "rationale": "Entropy measures uncertainty. If an outcome is certain (probability = 1), there is no uncertainty and no 'average surprise,' resulting in an entropy of 0.",
        "distractor_analysis": {
          "0": "Correct. Certainty means zero entropy.",
          "1": "Incorrect; 1 bit implies two equally likely states (like a fair coin flip).",
          "2": "Incorrect; infinity would imply infinite uncertainty, the opposite of certainty.",
          "3": "Incorrect; while log(0) is a limit, P*log(P) for P=0 is conventionally 0, and log(1) is 0."
        }
      },
      {
        "id": 3,
        "topic": "Entropy",
        "difficulty": "analysis",
        "question": "A system is moved from a state of uniform probability across all outcomes to a state where one outcome is highly likely and others are rare. What is the impact on the system's entropy?",
        "options": [
          "The entropy decreases because the system becomes more predictable.",
          "The entropy increases because the system becomes more ordered.",
          "The entropy remains constant because the number of possible states has not changed.",
          "The entropy increases because the surprise of the rare events is higher."
        ],
        "correct_index": 0,
        "rationale": "Entropy is maximized when all outcomes are equally likely (maximum uncertainty). Moving away from a uniform distribution toward a skewed one increases predictability and thus decreases entropy.",
        "distractor_analysis": {
          "0": "Correct. Predictability reduces the average surprise (entropy).",
          "1": "Incorrect; increasing order corresponds to a decrease in entropy.",
          "2": "Incorrect; entropy depends on the probability distribution, not just the count of possible states.",
          "3": "Incorrect; while rare events have high individual surprise, their low probability means they contribute less to the 'average' surprise (entropy)."
        }
      },
      {
        "id": 4,
        "topic": "Minimum Description Length (MDL)",
        "difficulty": "application",
        "question": "When applying the MDL principle to select between two models, which model should be chosen?",
        "options": [
          "The model that minimizes the sum of the model's description length and the data's description length given the model.",
          "The model with the highest number of parameters to ensure the lowest data loss.",
          "The model that ignores the data and focuses only on having the shortest code length for the model itself.",
          "The model that perfectly fits the training data regardless of its own complexity."
        ],
        "correct_index": 0,
        "rationale": "The MDL principle is a formalization of Occam's Razor, balancing the complexity of the model (L(M)) against its ability to compress the data (L(D|M)).",
        "distractor_analysis": {
          "0": "Correct. This is the core definition of the MDL principle.",
          "1": "Incorrect; high parameters increase model complexity, which MDL penalizes to prevent overfitting.",
          "2": "Incorrect; a model that ignores data is useless, as L(D|M) would be very high.",
          "3": "Incorrect; perfect fitting often leads to over-complex models (overfitting), which MDL avoids."
        }
      },
      {
        "id": 5,
        "topic": "Kolmogorov Complexity",
        "difficulty": "analysis",
        "question": "Two strings of the same length are compared: String A is '010101...01' and String B is a sequence of random coin flips. Which has higher Kolmogorov complexity?",
        "options": [
          "String B, because it cannot be significantly compressed by a shorter program.",
          "String A, because the alternating pattern requires complex logic to generate.",
          "Both have the same complexity because they have the same length.",
          "String A, because it contains more information content for a human observer."
        ],
        "correct_index": 0,
        "rationale": "Kolmogorov complexity is the size of the shortest program that generates a string. String A can be generated by a very short loop (print '01' n times), while String B has no pattern and requires a program almost as long as the string itself.",
        "distractor_analysis": {
          "0": "Correct. Randomness implies lack of compressible patterns.",
          "1": "Incorrect; simple patterns have low Kolmogorov complexity.",
          "2": "Incorrect; length is not the determinant; the structure/compressibility is.",
          "3": "Incorrect; 'information content' in this context is lower for patterns that are highly predictable."
        }
      },
      {
        "id": 6,
        "topic": "Kullback-Leibler (KL) Divergence",
        "difficulty": "recall",
        "question": "Why is the Kullback-Leibler (KL) Divergence referred to as an asymmetric measure?",
        "options": [
          "Because the divergence from P to Q is not necessarily equal to the divergence from Q to P.",
          "Because it can return negative values depending on which distribution is the reference.",
          "Because it only works for discrete distributions and not continuous ones.",
          "Because it measures the difference in mean but not the difference in variance."
        ],
        "correct_index": 0,
        "rationale": "KL(P||Q) measures the extra bits required to encode data from distribution P using a code optimized for Q. Swapping P and Q changes the reference, resulting in a different value; hence, it is not a true 'distance' metric.",
        "distractor_analysis": {
          "0": "Correct. This is the definition of asymmetry in this context.",
          "1": "Incorrect; according to Gibbs' inequality, KL divergence is always non-negative.",
          "2": "Incorrect; KL divergence is defined for both discrete and continuous variables.",
          "3": "Incorrect; KL divergence takes the entire distribution into account, not just specific moments."
        }
      },
      {
        "id": 7,
        "topic": "Mutual Information",
        "difficulty": "analysis",
        "question": "If the mutual information I(X; Y) between two random variables is 0, what can be definitively concluded about X and Y?",
        "options": [
          "X and Y are independent.",
          "X and Y have the same entropy.",
          "X and Y are perfectly correlated.",
          "Y provides some information about X, but X provides no information about Y."
        ],
        "correct_index": 0,
        "rationale": "Mutual information measures how much knowing one variable reduces the uncertainty about the other. If I(X; Y) = 0, no reduction in uncertainty occurs, which is the definition of independence.",
        "distractor_analysis": {
          "0": "Correct. Zero mutual information is synonymous with statistical independence.",
          "1": "Incorrect; variables can be independent even if they have different entropies.",
          "2": "Incorrect; perfect correlation would result in the maximum possible mutual information.",
          "3": "Incorrect; mutual information is symmetric: I(X; Y) = I(Y; X)."
        }
      },
      {
        "id": 8,
        "topic": "Huffman Compression",
        "difficulty": "recall",
        "question": "What is the significance of the 'prefix property' in Huffman coding?",
        "options": [
          "No codeword is a prefix of another, allowing for unique decoding without delimiters.",
          "All codewords must begin with the same bit to signal the start of a sequence.",
          "The most frequent symbol always has the longest prefix to ensure data integrity.",
          "It ensures that the compression is lossy so that more space can be saved."
        ],
        "correct_index": 0,
        "rationale": "The prefix property (or prefix-free property) ensures that as soon as a bit sequence matches a codeword, it can be decoded immediately because no longer valid codeword starts with that same sequence.",
        "distractor_analysis": {
          "0": "Correct. This enables 'instantaneous' and unique decoding.",
          "1": "Incorrect; this would make codewords indistinguishable and waste bits.",
          "2": "Incorrect; the most frequent symbol receives the *shortest* codeword.",
          "3": "Incorrect; Huffman coding is a lossless compression technique."
        }
      },
      {
        "id": 9,
        "topic": "Noiseless Coding Theorem",
        "difficulty": "analysis",
        "question": "According to Shannon's Noiseless Coding Theorem, what is the absolute lower bound on the average number of bits needed to represent a symbol from a source X?",
        "options": [
          "The entropy H(X) of the source.",
          "The log of the number of possible states in X.",
          "The reciprocal of the probability of the most frequent symbol.",
          "The length of the shortest codeword in a Huffman tree."
        ],
        "correct_index": 0,
        "rationale": "Shannon proved that no lossless compression can represent a source with fewer average bits than its entropy H(X).",
        "distractor_analysis": {
          "0": "Correct. Entropy is the fundamental limit of compression.",
          "1": "Incorrect; this is the length for a fixed-length code, which is only optimal if all states are equally likely.",
          "2": "Incorrect; this is related to individual surprise, not the average for the whole source.",
          "3": "Incorrect; the shortest codeword is just one part of the average; the entropy is the overall bound."
        }
      },
      {
        "id": 10,
        "topic": "Entropy",
        "difficulty": "application",
        "question": "In a binary system where P(X=1) = p, at what value of p is the entropy H(X) maximized?",
        "options": [
          "p = 0.5",
          "p = 0.0",
          "p = 1.0",
          "The entropy is constant regardless of p as long as the system is binary."
        ],
        "correct_index": 0,
        "rationale": "For a binary variable, uncertainty is highest when both outcomes are equally likely (a fair coin). This occurs at p = 0.5, where H(X) = 1 bit.",
        "distractor_analysis": {
          "0": "Correct. This is the peak of the binary entropy function.",
          "1": "Incorrect; at p=0, the outcome is certain (X=0), so entropy is 0.",
          "2": "Incorrect; at p=1, the outcome is certain (X=1), so entropy is 0.",
          "3": "Incorrect; entropy varies significantly with the probability distribution p."
        }
      },
      {
        "id": 11,
        "topic": "Information Content",
        "difficulty": "analysis",
        "question": "If two events A and B are independent, how does the information content of both events occurring simultaneously h(A ∩ B) relate to their individual information contents?",
        "options": [
          "h(A ∩ B) = h(A) + h(B)",
          "h(A ∩ B) = h(A) * h(B)",
          "h(A ∩ B) = max(h(A), h(B))",
          "h(A ∩ B) = log(h(A) + h(B))"
        ],
        "correct_index": 0,
        "rationale": "Information content is additive for independent events. Because P(A ∩ B) = P(A) * P(B) for independent events, taking the negative log converts the product into a sum.",
        "distractor_analysis": {
          "0": "Correct. This is the additivity property of information.",
          "1": "Incorrect; probabilities multiply, but information contents (logs) add.",
          "2": "Incorrect; information is not limited to the maximum of the parts.",
          "3": "Incorrect; the log is already part of the definition of h(x)."
        }
      },
      {
        "id": 12,
        "topic": "Kolmogorov Complexity",
        "difficulty": "application",
        "question": "Why is the Minimum Description Length (MDL) considered equivalent to Kolmogorov Complexity in a practical sense?",
        "options": [
          "Both seek the shortest possible representation of data to find the underlying regularities.",
          "Both require infinite computing power to calculate for any given string.",
          "Both are only applicable to binary strings and not natural language.",
          "Neither considers the complexity of the model, only the size of the data."
        ],
        "correct_index": 0,
        "rationale": "MDL and Kolmogorov complexity both view 'understanding' or 'learning' as 'compressing.' The best explanation for data is the one that allows for the shortest description of that data.",
        "distractor_analysis": {
          "0": "Correct. They share the same underlying philosophical goal.",
          "1": "Incorrect; while Kolmogorov complexity is non-computable, MDL is a practical framework used in statistics.",
          "2": "Incorrect; they are general concepts applicable to any data type.",
          "3": "Incorrect; MDL explicitly balances model complexity and data fit; Kolmogorov includes the program (model) size."
        }
      },
      {
        "id": 13,
        "topic": "Mutual Information",
        "difficulty": "analysis",
        "question": "How does mutual information I(X; Y) relate to the entropies H(X) and H(X|Y)?",
        "options": [
          "I(X; Y) = H(X) - H(X|Y)",
          "I(X; Y) = H(X) + H(X|Y)",
          "I(X; Y) = H(X|Y) - H(X)",
          "I(X; Y) = H(X) / H(X|Y)"
        ],
        "correct_index": 0,
        "rationale": "Mutual information is the reduction in the uncertainty of X given the knowledge of Y. This is calculated as the original entropy of X minus the remaining (conditional) entropy of X after Y is known.",
        "distractor_analysis": {
          "0": "Correct. Reduction in uncertainty is the core definition.",
          "1": "Incorrect; this would imply that knowing Y increases the uncertainty of X.",
          "2": "Incorrect; this would result in a negative value, but mutual information is non-negative.",
          "3": "Incorrect; the relationship is based on subtraction (difference in bits), not division."
        }
      },
      {
        "id": 14,
        "topic": "Kullback-Leibler (KL) Divergence",
        "difficulty": "application",
        "question": "If you use a probability distribution Q to design a code for a source that actually follows distribution P, what does KL(P||Q) represent?",
        "options": [
          "The average number of extra bits wasted per symbol due to the mismatch.",
          "The total number of bits required to send the entire message.",
          "The probability that the receiver will misinterpret the message.",
          "The minimum possible code length achievable for distribution P."
        ],
        "correct_index": 0,
        "rationale": "KL divergence measures 'relative entropy.' It quantifies the efficiency loss (in bits) when an imperfect model (Q) is used to approximate the true distribution (P).",
        "distractor_analysis": {
          "0": "Correct. It is the overhead or 'waste' due to using the wrong distribution.",
          "1": "Incorrect; the total bits would be H(P) + KL(P||Q).",
          "2": "Incorrect; KL divergence is a measure of coding efficiency, not error probability (in a noiseless context).",
          "3": "Incorrect; that is simply the entropy H(P)."
        }
      },
      {
        "id": 15,
        "topic": "Huffman Compression",
        "difficulty": "analysis",
        "question": "In a scenario where one symbol has a probability of 0.9 and three other symbols have probabilities of 0.033 each, what behavior would you expect from a Huffman code?",
        "options": [
          "The 0.9 probability symbol will be assigned a 1-bit code.",
          "All symbols will be assigned 2-bit codes because there are four possible symbols.",
          "The symbol with 0.9 probability will have a code longer than the 0.033 symbols.",
          "The code will be less efficient than a simple fixed-length code."
        ],
        "correct_index": 0,
        "rationale": "Huffman coding assigns shorter codes to more frequent symbols. With one symbol dominant at 0.9, it will inevitably be placed at the highest level of the tree, receiving a 1-bit code.",
        "distractor_analysis": {
          "0": "Correct. High frequency equals short code length.",
          "1": "Incorrect; that describes a fixed-length code, which is not what Huffman produces here.",
          "2": "Incorrect; this contradicts the core logic of Huffman coding.",
          "3": "Incorrect; Huffman is always at least as efficient as fixed-length coding for any non-uniform distribution."
        }
      },
      {
        "id": 16,
        "topic": "Entropy",
        "difficulty": "analysis",
        "question": "If we define a continuous random variable X, which distribution maximizes the entropy H[X] for a given variance?",
        "options": [
          "The Normal (Gaussian) distribution.",
          "The Uniform distribution.",
          "The Bernoulli distribution.",
          "The Zipfian distribution."
        ],
        "correct_index": 0,
        "rationale": "As noted in slide 12, for a continuous random variable, entropy is maximized when the distribution is Normal (Gaussian) for a fixed mean and variance.",
        "distractor_analysis": {
          "0": "Correct. This is a fundamental property of the Gaussian distribution in information theory.",
          "1": "Incorrect; Uniform maximizes entropy for a discrete variable with a fixed range, but not for a continuous variable with fixed variance.",
          "2": "Incorrect; Bernoulli is a discrete distribution.",
          "3": "Incorrect; Zipfian is a discrete power-law distribution typical of natural language, not maximum entropy."
        }
      },
      {
        "id": 17,
        "topic": "Minimum Description Length (MDL)",
        "difficulty": "analysis",
        "question": "In the context of MDL, how does 'Occam's Razor' justify the preference for simpler models?",
        "options": [
          "Simpler models have shorter description lengths, reducing the total cost unless the complex model fits significantly better.",
          "Simpler models are always more accurate in predicting unseen data, regardless of the training set.",
          "Occam's Razor states that complexity is an inherent sign of data noise.",
          "MDL prefers simpler models only when the amount of available data is infinite."
        ],
        "correct_index": 0,
        "rationale": "MDL treats model selection as a trade-off. A simpler model is easier to describe (short L(M)). We only accept a more complex model (longer L(M)) if it provides a much better fit (shorter L(D|M)).",
        "distractor_analysis": {
          "0": "Correct. The 'cost' of the model is its description length.",
          "1": "Incorrect; simplicity does not guarantee accuracy, but it protects against overfitting.",
          "2": "Incorrect; Occam's Razor is a heuristic preference for simplicity, not a statement that all complexity is noise.",
          "3": "Incorrect; MDL is especially useful for finite, limited data sets to prevent overfitting."
        }
      },
      {
        "id": 18,
        "topic": "Noisy-Channel Coding Theorem",
        "difficulty": "application",
        "question": "What happens if the source information rate R exceeds the channel capacity C?",
        "options": [
          "Reliable, error-free transmission becomes impossible.",
          "The transmission will simply take longer to complete, but remain error-free.",
          "The encoder will automatically reduce the entropy of the source to match C.",
          "The channel capacity C will increase to accommodate the higher rate R."
        ],
        "correct_index": 0,
        "rationale": "Shannon's Noisy-Channel Coding Theorem states that error-free transmission is only possible if the rate R is less than or equal to the capacity C. If R > C, errors are inevitable.",
        "distractor_analysis": {
          "0": "Correct. Capacity is a hard physical/mathematical limit for reliable communication.",
          "1": "Incorrect; errors cannot be eliminated by simply waiting longer if the rate exceeds capacity.",
          "2": "Incorrect; the encoder cannot change the source's entropy without losing information (lossy compression).",
          "3": "Incorrect; capacity is an inherent fixed property of the channel and its noise levels."
        }
      },
      {
        "id": 19,
        "topic": "Information Content",
        "difficulty": "application",
        "question": "A weather station predicts 'Sunny' with 95% probability and 'Earthquake' with 0.01% probability. Which report carries more information content if it actually occurs?",
        "options": [
          "The 'Earthquake' report, because it is much more surprising.",
          "The 'Sunny' report, because it is more likely to be correct.",
          "Both carry the same information because they come from the same source.",
          "Neither carries information until the event is verified by a second source."
        ],
        "correct_index": 0,
        "rationale": "Information content is h(x) = -log2 P(x). Since 0.0001 is much smaller than 0.95, its negative log is much higher, reflecting higher surprise/information.",
        "distractor_analysis": {
          "0": "Correct. Rarity equals high information.",
          "1": "Incorrect; likelihood reduces information content (surprise).",
          "2": "Incorrect; information depends on the probability of the specific event, not the source identity.",
          "3": "Incorrect; information content is a property of the probability of the message itself."
        }
      },
      {
        "id": 20,
        "topic": "Entropy",
        "difficulty": "analysis",
        "question": "If you are told that the joint entropy H(X, Y) is exactly equal to H(X) + H(Y), what is the value of the mutual information I(X; Y)?",
        "options": [
          "0 bits",
          "1 bit",
          "It depends on whether X and Y are continuous or discrete.",
          "It is equal to the conditional entropy H(X|Y)."
        ],
        "correct_index": 0,
        "rationale": "The property H(X, Y) = H(X) + H(Y) is the definition of additivity for independent variables. As established earlier, independent variables share 0 mutual information.",
        "distractor_analysis": {
          "0": "Correct. No overlap in information means mutual information is zero.",
          "1": "Incorrect; there is no reason for it to be 1.",
          "2": "Incorrect; this identity holds for both types if they are independent.",
          "3": "Incorrect; if they are independent, H(X|Y) = H(X), which is usually not zero."
        }
      },
      {
        "id": 21,
        "topic": "Kullback-Leibler (KL) Divergence",
        "difficulty": "analysis",
        "question": "What is the result of KL(P||Q) if there exists a state 'x' such that P(x) > 0 but Q(x) = 0?",
        "options": [
          "The divergence becomes infinite.",
          "The divergence becomes 0 because the state is ignored.",
          "The divergence is calculated only for the states where both are non-zero.",
          "The divergence becomes negative, indicating an impossible model."
        ],
        "correct_index": 0,
        "rationale": "KL divergence involves the term P(x) * log(P(x)/Q(x)). If Q(x) is 0 while P(x) is non-zero, the ratio involves division by zero, leading to infinite divergence. This means model Q is 'infinitely' bad at representing P.",
        "distractor_analysis": {
          "0": "Correct. You cannot use a model that predicts an event is impossible (Q=0) if that event actually happens (P>0).",
          "1": "Incorrect; the mismatch is catastrophic and cannot be ignored.",
          "2": "Incorrect; the definition requires the summation over all states in the domain of P.",
          "3": "Incorrect; KL divergence can never be negative."
        }
      },
      {
        "id": 22,
        "topic": "Kolmogorov Complexity",
        "difficulty": "application",
        "question": "A data scientist finds that a 1GB file can be compressed down to 1KB. What does this suggest about the file's Kolmogorov complexity?",
        "options": [
          "It has very low Kolmogorov complexity because it can be generated by a very small program.",
          "It has very high Kolmogorov complexity because it contains a lot of data.",
          "The Kolmogorov complexity is exactly 1KB.",
          "The Kolmogorov complexity cannot be determined because compression is lossy."
        ],
        "correct_index": 0,
        "rationale": "Kolmogorov complexity is essentially the limit of lossless compression. If a massive file can be represented by a tiny one, the 'true' amount of information (complexity) is small.",
        "distractor_analysis": {
          "0": "Correct. High compressibility implies low algorithmic entropy.",
          "1": "Incorrect; file size (data volume) is not the same as complexity (information).",
          "2": "Incorrect; 1KB is an upper bound on the complexity, but the true complexity might be even smaller.",
          "3": "Incorrect; the scenario implies we are talking about the information content, and Huffman/LZW are lossless."
        }
      },
      {
        "id": 23,
        "topic": "Huffman Compression",
        "difficulty": "analysis",
        "question": "Which of the following scenarios would render a Huffman code no more efficient than a fixed-length code?",
        "options": [
          "All possible symbols in the source have exactly the same probability.",
          "The number of symbols is a power of 2.",
          "The source symbols are highly correlated with each other.",
          "The entropy of the source is very high."
        ],
        "correct_index": 0,
        "rationale": "Huffman coding gains efficiency by exploiting non-uniform probabilities. If every symbol is equally likely (uniform distribution), every symbol will end up at the same depth in the tree, behaving like a fixed-length code.",
        "distractor_analysis": {
          "0": "Correct. Uniformity removes the advantage of variable-length coding.",
          "1": "Incorrect; even if the count is a power of 2, if probabilities are skewed, Huffman is better.",
          "2": "Incorrect; correlation often allows for even better compression (like LZW), but it doesn't make Huffman worse.",
          "3": "Incorrect; High entropy means you need more bits, but if it's non-uniform, Huffman still helps."
        }
      },
      {
        "id": 24,
        "topic": "Entropy",
        "difficulty": "analysis",
        "question": "How does the 'Conditional Entropy' H(Y|X) differ conceptually from the 'Joint Entropy' H(X, Y)?",
        "options": [
          "H(Y|X) is the uncertainty remaining in Y after X is known, while H(X, Y) is the total uncertainty of the pair.",
          "H(Y|X) is always greater than or equal to H(X, Y).",
          "H(Y|X) measures the information shared between X and Y, while H(X, Y) measures the information they don't share.",
          "H(Y|X) only applies to independent variables, while H(X, Y) applies to dependent ones."
        ],
        "correct_index": 0,
        "rationale": "H(X, Y) is the 'total' information in the system. H(Y|X) is a 'subset' of that—specifically the information in Y that is not already explained by X.",
        "distractor_analysis": {
          "0": "Correct. This captures the logic of 'remaining uncertainty.'",
          "1": "Incorrect; H(X, Y) = H(X) + H(Y|X), so H(X, Y) is always greater than or equal to H(Y|X).",
          "2": "Incorrect; the shared information is Mutual Information I(X; Y).",
          "3": "Incorrect; both concepts apply to any set of random variables."
        }
      },
      {
        "id": 25,
        "topic": "Minimum Description Length (MDL)",
        "difficulty": "analysis",
        "question": "Why does MDL tend to naturally favor models that generalize well to new data?",
        "options": [
          "Because models that overfit are overly complex, resulting in a high model description length L(M) that MDL penalizes.",
          "Because MDL requires that all models be tested on a separate validation set.",
          "Because MDL assumes the data is noiseless, forcing models to find only true patterns.",
          "Because MDL only considers the error rate on the training data."
        ],
        "correct_index": 0,
        "rationale": "Overfitting usually involves adding many parameters to 'memorize' noise. In MDL, these parameters increase L(M). MDL only allows this if the reduction in L(D|M) is large enough to compensate, which noise-fitting usually doesn't provide.",
        "distractor_analysis": {
          "0": "Correct. The complexity penalty in L(M) acts as a regularizer.",
          "1": "Incorrect; MDL is a criterion applied to the training set/model itself, not a validation procedure.",
          "2": "Incorrect; MDL explicitly accounts for the possibility of noise by looking for the most compact representation.",
          "3": "Incorrect; if it only considered training error, it would always pick the most complex model."
        }
      },
      {
        "id": 26,
        "topic": "Information Content",
        "difficulty": "recall",
        "question": "What is the fundamental unit of information assumed in the slide deck?",
        "options": [
          "The bit",
          "The byte",
          "The nats",
          "The symbol"
        ],
        "correct_index": 0,
        "rationale": "Slide 4 explicitly states: 'The bit is the most fundamental unit of information.'",
        "distractor_analysis": {
          "0": "Correct. Bits are the standard based on base-2 logarithms used in the slides.",
          "1": "Incorrect; a byte is a collection of 8 bits, not the 'fundamental' unit.",
          "2": "Incorrect; nats use natural logarithms (base e), which were not the primary focus.",
          "3": "Incorrect; a symbol is what carries information, not the unit of measure for the information itself."
        }
      },
      {
        "id": 27,
        "topic": "Noisy Channels",
        "difficulty": "application",
        "question": "In the repetition code example (Slide 24), why is the bit '0' sent as '000' instead of just '0'?",
        "options": [
          "To introduce systematic redundancy so that errors can be detected and corrected.",
          "To increase the information content of the message.",
          "Because the channel requires all messages to be exactly 3 bits long.",
          "To increase the transmission rate R above the channel capacity C."
        ],
        "correct_index": 0,
        "rationale": "Redundancy is the primary tool for dealing with noise. By sending multiple copies, the receiver can use a 'majority vote' to reconstruct the original signal even if one bit is flipped.",
        "distractor_analysis": {
          "0": "Correct. Redundancy allows for error resilience.",
          "1": "Incorrect; redundancy actually *decreases* the average information per transmitted bit.",
          "2": "Incorrect; repetition is a choice for reliability, not a requirement of bit length.",
          "3": "Incorrect; increasing redundancy *decreases* the rate R."
        }
      },
      {
        "id": 28,
        "topic": "Mutual Information",
        "difficulty": "analysis",
        "question": "Which of the following best describes the 'symmetry' of mutual information?",
        "options": [
          "I(X; Y) is always equal to I(Y; X).",
          "The mutual information is equal to the sum of the individual entropies.",
          "Mutual information is only symmetric if X and Y have the same number of states.",
          "The symmetry implies that the joint entropy H(X, Y) is zero."
        ],
        "correct_index": 0,
        "rationale": "Mutual information measures the information shared between two variables. The amount of information X tells you about Y is identically the amount of information Y tells you about X.",
        "distractor_analysis": {
          "0": "Correct. Mutual information is a symmetric measure.",
          "1": "Incorrect; that would be true only if they were independent and the result was joint entropy (not mutual info).",
          "2": "Incorrect; symmetry is a property of the functional form, independent of domain size.",
          "3": "Incorrect; joint entropy is only zero if both variables are deterministic constants."
        }
      },
      {
        "id": 29,
        "topic": "Zipf's Law",
        "difficulty": "recall",
        "question": "According to Zipf's Law, how is the frequency of a word related to its rank in a frequency table?",
        "options": [
          "The frequency is inversely proportional to the rank.",
          "The frequency increases as the rank increases.",
          "The frequency is the square of the rank.",
          "There is no predictable relationship between frequency and rank."
        ],
        "correct_index": 0,
        "rationale": "Zipf's Law states f(t) ≈ C / r(t), where f is frequency and r is rank. This means the most frequent word (rank 1) occurs twice as often as the second most frequent (rank 2), and so on.",
        "distractor_analysis": {
          "0": "Correct. This is the definition of Zipf's power law.",
          "1": "Incorrect; higher rank (e.g., the 100th word) means lower frequency.",
          "2": "Incorrect; the relationship is inverse, not a square.",
          "3": "Incorrect; Zipf's Law is a well-documented empirical observation in linguistics."
        }
      },
      {
        "id": 30,
        "topic": "Heap's Law",
        "difficulty": "analysis",
        "question": "What is the primary implication of Heap's Law for a data scientist working with massive text corpora?",
        "options": [
          "The vocabulary size grows sublinearly, meaning you will continue to encounter new words, but at a decreasing rate.",
          "The vocabulary size is fixed once the document reaches 100,000 words.",
          "Every new document added to a corpus will contain exactly the same number of unique words.",
          "The number of unique words is always half of the total number of words."
        ],
        "correct_index": 0,
        "rationale": "Heap's Law (V = Kn^β with β < 1) indicates that the vocabulary (V) grows as document size (n) increases, but the rate of discovery of new words slows down over time.",
        "distractor_analysis": {
          "0": "Correct. Sublinear growth is the key characteristic.",
          "1": "Incorrect; the vocabulary continues to grow indefinitely, just more slowly.",
          "2": "Incorrect; word counts vary by document and topic.",
          "3": "Incorrect; the ratio of unique words to total words changes as the corpus grows."
        }
      },
      {
        "id": 31,
        "topic": "TF-IDF",
        "difficulty": "analysis",
        "question": "In the TF-IDF weighting scheme, what is the purpose of the 'Inverse Document Frequency' (IDF) component?",
        "options": [
          "To down-weight common words (like 'the' or 'is') that appear in many documents and thus carry little discriminative information.",
          "To ensure that longer documents are given higher priority in search results.",
          "To count how many times a specific term appears within a single document.",
          "To normalize the word counts so they sum to exactly 1.0."
        ],
        "correct_index": 0,
        "rationale": "IDF measures how unique a word is across the whole corpus. If a word appears everywhere, it's likely a 'stop word' and not useful for identifying the specific topic of a single document.",
        "distractor_analysis": {
          "0": "Correct. IDF captures the 'representativeness' or 'specificity' of a term.",
          "1": "Incorrect; TF-IDF often uses normalization to *remove* the influence of document length.",
          "2": "Incorrect; that is the 'Term Frequency' (TF) component.",
          "3": "Incorrect; TF-IDF weights are not probabilities and do not need to sum to 1."
        }
      },
      {
        "id": 32,
        "topic": "Entropy",
        "difficulty": "application",
        "question": "If you have an 8-state system where all states are equally likely, how many bits on average are needed to encode a state?",
        "options": [
          "3 bits",
          "8 bits",
          "1 bit",
          "log(8) / log(10) bits"
        ],
        "correct_index": 0,
        "rationale": "As shown in the example on slide 10, for 8 equally likely states, H(X) = log2(8) = 3 bits.",
        "distractor_analysis": {
          "0": "Correct. 2^3 = 8.",
          "1": "Incorrect; 8 bits would be needed for 256 states.",
          "2": "Incorrect; 1 bit only covers 2 states.",
          "3": "Incorrect; this is a change-of-base formula that doesn't result in bits (base-2)."
        }
      },
      {
        "id": 33,
        "topic": "Kullback-Leibler (KL) Divergence",
        "difficulty": "analysis",
        "question": "In Jensen-Shannon (JS) Divergence, why is it often preferred over standard KL Divergence in machine learning applications?",
        "options": [
          "JS Divergence is symmetric and always provides a finite value.",
          "JS Divergence is easier to calculate because it ignores the logarithm.",
          "JS Divergence allows for negative values which help in gradient descent.",
          "JS Divergence only requires one distribution instead of two."
        ],
        "correct_index": 0,
        "rationale": "As shown on slide 15, JS divergence is a symmetric measure based on KL. Because it compares distributions to their average, it avoids the 'division by zero' (infinite) issues of KL divergence.",
        "distractor_analysis": {
          "0": "Correct. Symmetry and finiteness are its two primary advantages.",
          "1": "Incorrect; it is still based on KL divergence, which uses logarithms.",
          "2": "Incorrect; JS divergence, like KL, is non-negative.",
          "3": "Incorrect; all divergence measures require two distributions to compare."
        }
      },
      {
        "id": 34,
        "topic": "Noiseless Coding Theorem",
        "difficulty": "analysis",
        "question": "The Lempel-Ziv-Welch (LZW) algorithm is mentioned as a 'more sophisticated' algorithm. In what conceptual way does it extend Shannon’s basic theorem?",
        "options": [
          "It encodes sequences of states (blocks) rather than individual symbols, capturing inter-symbol dependencies.",
          "It allows for lossy compression, which Shannon’s Noiseless theorem prohibits.",
          "It ignores entropy entirely and uses a purely deterministic approach.",
          "It only works if the source has zero entropy."
        ],
        "correct_index": 0,
        "rationale": "While basic Huffman coding works on single symbols, LZW builds a dictionary of sequences. This allows it to compress data where the 'surprise' of a symbol depends on the symbols preceding it.",
        "distractor_analysis": {
          "0": "Correct. Block-encoding/dictionary methods exploit dependencies to reach the entropy limit of the *source*.",
          "1": "Incorrect; LZW is a lossless algorithm.",
          "2": "Incorrect; LZW is fundamentally tied to the information content and entropy of the data it processes.",
          "3": "Incorrect; if entropy were zero, the file would be one repeating character and trivial to compress."
        }
      },
      {
        "id": 35,
        "topic": "Entropy",
        "difficulty": "recall",
        "question": "What does the term 'Joint Entropy' H(X, Y) represent?",
        "options": [
          "The total uncertainty contained in a system of two random variables considered together.",
          "The average information that X and Y share.",
          "The ratio of the entropy of X to the entropy of Y.",
          "The difference between the entropy of the sender and the receiver."
        ],
        "correct_index": 0,
        "rationale": "Joint entropy is the entropy of the joint distribution of two variables; it measures the total uncertainty of the pair (X, Y).",
        "distractor_analysis": {
          "0": "Correct. Total system uncertainty.",
          "1": "Incorrect; shared information is Mutual Information.",
          "2": "Incorrect; joint entropy is an additive/subtractive concept, not a ratio.",
          "3": "Incorrect; this is not a standard definition in information theory."
        }
      },
      {
        "id": 36,
        "topic": "Huffman Compression",
        "difficulty": "application",
        "question": "If you add a 9th possible state with a very low probability to the example on Slide 18, how would the Huffman tree change?",
        "options": [
          "The new state would be added at the deepest possible level of the tree, likely sharing a parent with the previous least-likely state.",
          "The entire tree would be discarded and replaced with a fixed-length 4-bit code.",
          "The most frequent state (x1) would have its codeword length increased to accommodate the new state.",
          "The tree would become a perfectly balanced binary tree."
        ],
        "correct_index": 0,
        "rationale": "Huffman's bottom-up construction always starts by combining the two least frequent nodes. A new, very rare state would simply pair up with the current rarest state at the bottom of the tree.",
        "distractor_analysis": {
          "0": "Correct. Rare states are pushed to the bottom (longest codes).",
          "1": "Incorrect; Huffman is dynamic and adapts to the number of states and their probabilities.",
          "2": "Incorrect; the top of the tree (frequent symbols) remains short unless the probabilities change significantly.",
          "3": "Incorrect; balanced trees only occur when probabilities are near-equal."
        }
      },
      {
        "id": 37,
        "topic": "Kolmogorov Complexity",
        "difficulty": "analysis",
        "question": "Why is it impossible to write a program that calculates the exact Kolmogorov Complexity for any arbitrary string?",
        "options": [
          "Because it is related to the Halting Problem; you cannot always determine if a shorter program will eventually produce the string.",
          "Because the complexity depends on the specific programming language used.",
          "Because strings can be infinitely long, making the calculation take infinite time.",
          "Because the value changes every time the data is compressed."
        ],
        "correct_index": 0,
        "rationale": "Kolmogorov complexity is 'uncomputable' because to find the absolute shortest program, you would have to test all possible programs. The Halting Problem prevents us from knowing if a candidate program will ever finish and output the string.",
        "distractor_analysis": {
          "0": "Correct. This is the theoretical basis for its uncomputability.",
          "1": "Incorrect; while the exact value might vary by a constant, the concept is universal (Invariance Theorem).",
          "2": "Incorrect; complexity is defined for finite strings; length is not the issue, logic is.",
          "3": "Incorrect; Kolmogorov complexity is a theoretical property of the string itself, not a measurement of a specific compression run."
        }
      },
      {
        "id": 38,
        "topic": "Information Content",
        "difficulty": "analysis",
        "question": "What is the consequence of the 'closed world assumption' mentioned in Slide 17 for information theory?",
        "options": [
          "It assumes the sender and receiver share the same semantic context, allowing context to be ignored.",
          "It assumes that no new information can ever be created in the universe.",
          "It limits communication to happen only between two computers in the same room.",
          "It assumes that information is always lost during transmission."
        ],
        "correct_index": 0,
        "rationale": "Standard information theory (Shannon) focuses on the *syntax* (the bits). It assumes the meaning (semantics) is already agreed upon or irrelevant to the technical task of transmission.",
        "distractor_analysis": {
          "0": "Correct. Semantic context is factored out by this assumption.",
          "1": "Incorrect; information theory is about the transmission of *new* messages (news).",
          "2": "Incorrect; 'closed' refers to the shared knowledge/rules, not physical location.",
          "3": "Incorrect; information theory assumes information is *measurable* and *never lost* (unless the channel is noisy)."
        }
      },
      {
        "id": 39,
        "topic": "Entropy",
        "difficulty": "analysis",
        "question": "Compare the entropy of a fair 6-sided die and a fair 20-sided die. Which is true?",
        "options": [
          "The 20-sided die has higher entropy because it has more possible outcomes, increasing uncertainty.",
          "Both have the same entropy because they are both 'fair'.",
          "The 6-sided die has higher entropy because each outcome is more likely.",
          "Entropy cannot be compared between systems with different numbers of states."
        ],
        "correct_index": 0,
        "rationale": "For uniform distributions, H(X) = log2(n). Since 20 > 6, log2(20) > log2(6). There is more uncertainty in the 20-sided die.",
        "distractor_analysis": {
          "0": "Correct. More states at equal probability equals more uncertainty.",
          "1": "Incorrect; 'fairness' means uniform distribution, but the number of outcomes still matters.",
          "2": "Incorrect; higher probability of individual outcomes actually *lowers* entropy if the number of states is small.",
          "3": "Incorrect; entropy is a universal measure in bits and can be compared across any discrete variables."
        }
      },
      {
        "id": 40,
        "topic": "Minimum Description Length (MDL)",
        "difficulty": "recall",
        "question": "Which historical figure's philosophy is the basis for the Minimum Description Length principle?",
        "options": [
          "William of Ockham",
          "Claude Shannon",
          "Andrey Kolmogorov",
          "Thomas Bayes"
        ],
        "correct_index": 0,
        "rationale": "Slide 13 explicitly links MDL to Occam's Razor, attributed to William of Ockham (1285–1349).",
        "distractor_analysis": {
          "0": "Correct. The principle of parsimony.",
          "1": "Incorrect; Shannon provided the math for information theory, but MDL is the application of Ockham's philosophy.",
          "2": "Incorrect; Kolmogorov developed algorithmic information theory, a cousin of MDL.",
          "3": "Incorrect; Bayes is the father of Bayesian probability, which is related but not the source of the 'simplest hypothesis' razor."
        }
      },
      {
        "id": 41,
        "topic": "Channel Capacity",
        "difficulty": "analysis",
        "question": "What does 'Channel Capacity' C represent in a noisy channel?",
        "options": [
          "The maximum rate at which information can be transmitted with an arbitrarily small error probability.",
          "The physical limit on the number of bits that can be stored in the cable.",
          "The average noise level of the channel measured in decibels.",
          "The total length of the message divided by the time it takes to send it."
        ],
        "correct_index": 0,
        "rationale": "Channel capacity is defined as the maximum mutual information between the input and output, which defines the upper limit for reliable communication.",
        "distractor_analysis": {
          "0": "Correct. This is Shannon's definition of capacity.",
          "1": "Incorrect; capacity is a rate (bits per use/second), not a static storage volume.",
          "2": "Incorrect; noise affects capacity, but capacity is the *result* of that noise on information flow.",
          "3": "Incorrect; this would just be the raw transmission speed, not the limit for error-free delivery."
        }
      },
      {
        "id": 42,
        "topic": "Mutual Information",
        "difficulty": "application",
        "question": "If X is a message and Y is a noisy version of that message, what does I(X; Y) tell the receiver?",
        "options": [
          "How many bits of the original message X can be recovered from the received message Y.",
          "The exact number of bit-flips that occurred during transmission.",
          "The entropy of the noise in the channel.",
          "The total length of the message X."
        ],
        "correct_index": 0,
        "rationale": "Mutual information quantifies the overlap. In a communication context, it is the amount of information that successfully 'passed through' the noise from X to Y.",
        "distractor_analysis": {
          "0": "Correct. It's the recoverable/shared information.",
          "1": "Incorrect; I(X;Y) is a statistical average, not a count of specific errors.",
          "2": "Incorrect; this is related to the conditional entropy H(Y|X).",
          "3": "Incorrect; mutual information is about content, not the raw length."
        }
      },
      {
        "id": 43,
        "topic": "Entropy",
        "difficulty": "analysis",
        "question": "Why is the entropy of a language (like English) much lower than the log of the number of words in its dictionary?",
        "options": [
          "Because languages have significant redundancy and rules (grammar, common phrases) that make words predictable.",
          "Because humans only use a small fraction of the words available in a dictionary.",
          "Because English words are generally short in length.",
          "Because the 'closed world assumption' does not apply to natural languages."
        ],
        "correct_index": 0,
        "rationale": "Entropy is maximized only for uniform, independent outcomes. In language, letters and words follow strict patterns (e.g., 'q' is usually followed by 'u'), which significantly reduces uncertainty and thus entropy.",
        "distractor_analysis": {
          "0": "Correct. Context and structure reduce entropy.",
          "1": "Incorrect; even if we used all words, if we used them in predictable patterns, entropy would be low.",
          "2": "Incorrect; word length (physical size) is not information entropy.",
          "3": "Incorrect; the assumption is a modeling tool, not the cause of language's statistical structure."
        }
      },
      {
        "id": 44,
        "topic": "Repetition Codes",
        "difficulty": "analysis",
        "question": "In the repetition code example (Slide 24), what happens to the 'Source Information Rate' as you increase the number of repetitions (e.g., from 3 to 101)?",
        "options": [
          "The rate decreases, because you are sending more 'empty' bits for every 'real' bit of information.",
          "The rate increases, because the message is now more likely to be correct.",
          "The rate stays the same, because the source entropy has not changed.",
          "The rate becomes equal to the channel capacity."
        ],
        "correct_index": 0,
        "rationale": "Rate R is (useful bits / total bits). By sending 101 bits for every 1 source bit, the rate R = 1/101, which is much lower than R = 1/3. You trade off speed for reliability.",
        "distractor_analysis": {
          "0": "Correct. Efficiency is sacrificed for error correction.",
          "1": "Incorrect; reliability increases, but the *rate* of transmission of new info decreases.",
          "2": "Incorrect; the 'Source Information Rate' refers to the ratio of information to symbols sent over the channel.",
          "3": "Incorrect; rate and capacity are independent; rate is a choice, capacity is a limit."
        }
      },
      {
        "id": 45,
        "topic": "TF-IDF",
        "difficulty": "application",
        "question": "If the term 'Artificial' appears 10 times in Document A and 10 times in Document B, but Document A is twice as long as Document B, which will have a higher Term Frequency (TF) for that word?",
        "options": [
          "Document B, because the term is more concentrated relative to the document length.",
          "Document A, because it has more total content.",
          "Both will have the same TF because the raw count is 10.",
          "Neither; TF can only be calculated for the most frequent word in the corpus."
        ],
        "correct_index": 0,
        "rationale": "Slide 33 shows TF as a normalized measure (count / max_count or total_words). A word appearing 10 times in a short document represents a higher 'density' or 'importance' for that document than 10 times in a long one.",
        "distractor_analysis": {
          "0": "Correct. Normalization makes TF relative to document size.",
          "1": "Incorrect; raw counts favor long documents, which normalization specifically corrects.",
          "2": "Incorrect; information retrieval requires accounting for document length.",
          "3": "Incorrect; TF is calculated for any term in any document."
        }
      },
      {
        "id": 46,
        "topic": "Entropy",
        "difficulty": "recall",
        "question": "What is the lower bound of entropy H(X) for any discrete random variable?",
        "options": [
          "0",
          "-1",
          "1",
          "Negative infinity"
        ],
        "correct_index": 0,
        "rationale": "Slide 12: log n ≥ H[X] ≥ 0. Entropy is a measure of uncertainty; you cannot have 'less than zero' uncertainty.",
        "distractor_analysis": {
          "0": "Correct. Zero represents absolute certainty.",
          "1": "Incorrect; probabilities are [0,1], and -P*log(P) is always non-negative.",
          "2": "Incorrect; entropy can be much smaller than 1 (e.g., a very biased coin).",
          "3": "Incorrect; this is physically and mathematically impossible for discrete entropy."
        }
      },
      {
        "id": 47,
        "topic": "Source Information Rate",
        "difficulty": "analysis",
        "question": "When is a source considered 'memory-less' in information theory?",
        "options": [
          "When the probability of the current symbol does not depend on any of the previous symbols.",
          "When the source cannot store any of the messages it has sent.",
          "When the entropy of the source is zero.",
          "When the source uses a fixed-length code for all messages."
        ],
        "correct_index": 0,
        "rationale": "As shown in Slide 26, a source is memory-less if the joint entropy of a block of symbols is simply the sum of their individual entropies, meaning they are independent.",
        "distractor_analysis": {
          "0": "Correct. This is the definition of independence in a sequence.",
          "1": "Incorrect; 'memory' refers to statistical dependency, not hardware storage.",
          "2": "Incorrect; memory-less sources can have very high entropy (e.g., a sequence of fair coin flips).",
          "3": "Incorrect; coding choice is independent of the source's statistical properties."
        }
      },
      {
        "id": 48,
        "topic": "Ziv-Lempel Compression",
        "difficulty": "recall",
        "question": "In LZ77 compression, what does a triple (previous, length, new) represent?",
        "options": [
          "A pointer to a previous match, the length of that match, and the next character after the match.",
          "The probability of the symbol, its length in bits, and its new ASCII code.",
          "The distance to the end of the file, the length of the window, and a new dictionary index.",
          "The previous character, the length of the whole string, and a new bit sequence."
        ],
        "correct_index": 0,
        "rationale": "Slide 21: 'previous' is the distance to the previous occurrence, 'length' is the length of the string, and 'new' is the symbol following it.",
        "distractor_analysis": {
          "0": "Correct. This is the standard encoding for LZ77.",
          "1": "Incorrect; LZ77 is a dictionary/sliding window method, not a probability-based method like Huffman.",
          "2": "Incorrect; LZ77 looks backward, not toward the end of the file.",
          "3": "Incorrect; this does not match the sliding window logic described."
        }
      },
      {
        "id": 49,
        "topic": "Information Theory Overview",
        "difficulty": "recall",
        "question": "In what year and publication was the foundation of Information Theory established?",
        "options": [
          "1948, 'A Mathematical Theory of Communication'",
          "1952, 'The Art of Computer Programming'",
          "1936, 'On Computable Numbers'",
          "1925, 'Foundations of AI and Data Science'"
        ],
        "correct_index": 0,
        "rationale": "Slide 4 cites Claude Shannon's landmark publication in 1948 as the start of the field.",
        "distractor_analysis": {
          "0": "Correct. This is the 'bible' of Information Theory.",
          "1": "Incorrect; this is Donald Knuth's famous series started much later.",
          "2": "Incorrect; this is Alan Turing's paper on computation/Turing machines.",
          "3": "Incorrect; this is likely the title of the current course, not the historical paper."
        }
      },
      {
        "id": 50,
        "topic": "Mutual Information",
        "difficulty": "analysis",
        "question": "If you have two variables X and Y, and X perfectly determines Y (i.e., Y = f(X)), what is the relationship between I(X; Y) and H(Y)?",
        "options": [
          "I(X; Y) = H(Y)",
          "I(X; Y) = 0",
          "I(X; Y) = H(X) + H(Y)",
          "I(X; Y) = H(X) / H(Y)"
        ],
        "correct_index": 0,
        "rationale": "Mutual information is I(X; Y) = H(Y) - H(Y|X). If X determines Y, there is no uncertainty in Y once X is known, so H(Y|X) = 0. Therefore, I(X; Y) = H(Y). All information in Y is shared with X.",
        "distractor_analysis": {
          "0": "Correct. Knowing X tells you everything about Y.",
          "1": "Incorrect; this would only be true if they were independent, the opposite of this scenario.",
          "2": "Incorrect; this would imply they have no information in common.",
          "3": "Incorrect; mutual information is measured in bits (subtraction), not ratios."
        }
      }
    ]
  },
  "foundations-04": {
    "title": "Foundations of AI - Supervised Classification",
    "questions": [
      {
        "id": 1,
        "topic": "Feature Types",
        "difficulty": "recall",
        "question": "According to the slide on feature types, which property is characteristically absent in ordinal features but present in continuous features?",
        "options": [
          "Ordering/Ranking",
          "Scale/Unit measurement",
          "Median tendency",
          "Quantile dispersion"
        ],
        "correct_index": 1,
        "rationale": "As shown in the slide table, ordinal features possess 'Order' but lack 'Scale', whereas continuous features possess both.",
        "distractor_analysis": {
          "0": "Both ordinal and continuous features can be ordered.",
          "1": "Correct. Continuous features have a defined scale/distance between values.",
          "2": "The median is a valid measure of central tendency for ordinal features.",
          "3": "Quantiles are the standard way to measure dispersion for ordinal features."
        }
      },
      {
        "id": 2,
        "topic": "Feature Selection",
        "difficulty": "application",
        "question": "A data scientist is selecting features for a classification task. Based on the provided guidelines, which feature pair would be considered the most ideal for model efficiency?",
        "options": [
          "Two features that are highly correlated with each other and the target class.",
          "Two features that are independent of each other but both show strong class correlation.",
          "Two features that are extremely specific to individual training instances.",
          "Two features that provide general information across all classes equally."
        ],
        "correct_index": 1,
        "rationale": "Features should ideally be independent of each other to avoid redundancy but have strong correlation with the class to provide predictive power.",
        "distractor_analysis": {
          "0": "Correlated features are redundant and violate the preference for independence.",
          "1": "Correct. This maximizes information gain while minimizing redundancy.",
          "2": "Features that are too specific lead to overfitting.",
          "3": "Features that are too general provide no discriminative power between classes."
        }
      },
      {
        "id": 3,
        "topic": "Feature Transformations",
        "difficulty": "analysis",
        "question": "When transforming a 'Continuous' feature into an 'Ordinal' feature, what is the specific terminology used for this process on the slides?",
        "options": [
          "Normalization",
          "Calibration",
          "Discretization",
          "Grouping"
        ],
        "correct_index": 2,
        "rationale": "The transformation matrix on slide 7 explicitly labels the path from Continuous to Ordinal (or Categorical) as 'Discretization'.",
        "distractor_analysis": {
          "0": "Normalization is continuous-to-continuous scaling.",
          "1": "Calibration is used for Categorical/Ordinal to Continuous mapping.",
          "2": "Correct. It involves mapping continuous ranges to discrete bins.",
          "3": "Grouping is the process of merging existing Categorical values."
        }
      },
      {
        "id": 4,
        "topic": "Multi-class Classification",
        "difficulty": "recall",
        "question": "Which of the following models is explicitly noted as one that does NOT naturally generalize to multi-class classification, often requiring geometric adaptations?",
        "options": [
          "Naive Bayes",
          "Decision Trees",
          "Support Vector Machines",
          "Neural Networks"
        ],
        "correct_index": 2,
        "rationale": "Slide 12 states that geometric models like SVMs and Winnow do not naturally generalize to multiclass, unlike probabilistic or rule-based models.",
        "distractor_analysis": {
          "0": "Naive Bayes handles multi-class naturally via probability distributions.",
          "1": "Decision Trees naturally split into multiple leaves/classes.",
          "2": "Correct. SVM is inherently a binary geometric separator.",
          "3": "Neural Networks generalize via multi-unit output layers."
        }
      },
      {
        "id": 5,
        "topic": "Multi-class Strategy",
        "difficulty": "analysis",
        "question": "In a 'One-of' classification task involving 'k' classes, how is the final label for an instance determined after applying all classifiers separately?",
        "options": [
          "The label is assigned if any single classifier returns a positive result.",
          "The instance is assigned to the class that yields the maximum score.",
          "The decisions are independent; the instance can belong to multiple classes.",
          "A hierarchical tree determines the label based on a sequence of binary splits."
        ],
        "correct_index": 1,
        "rationale": "Slide 13 specifies that for 'One-of', we assign the instance to the class with the maximum score.",
        "distractor_analysis": {
          "0": "This describes a loose OR logic not mentioned in the slides.",
          "1": "Correct. The max score identifies the 'best fit' among exclusive classes.",
          "2": "This describes 'Any-of' (multi-label) classification.",
          "3": "This describes a hierarchical classifier, not the standard 'One-vs-Rest' logic."
        }
      },
      {
        "id": 6,
        "topic": "Overfitting",
        "difficulty": "application",
        "question": "If a Neural Network's performance is significantly higher on the training set than the test set, which adjustment based on the slide's theory would most likely mitigate this?",
        "options": [
          "Increasing the number of parameters to fit training data better.",
          "Reducing the training duration (learning time).",
          "Decreasing the size of the training set.",
          "Increasing the dimensionality of the feature space."
        ],
        "correct_index": 1,
        "rationale": "Slide 15 lists 'Learning is performed for too long' as a cause of overfitting; thus, reducing duration helps.",
        "distractor_analysis": {
          "0": "More parameters typically increase overfitting risk.",
          "1": "Correct. Stopping early prevents the model from memorizing noise.",
          "2": "Small training sets are a cause of overfitting, not a cure.",
          "3": "High dimensionality is a major driver of the 'Curse of Dimensionality' and overfitting."
        }
      },
      {
        "id": 7,
        "topic": "Curse of Dimensionality",
        "difficulty": "analysis",
        "question": "How does the 'Curse of Dimensionality' specifically affect distance-based similarity measures like those used in KNN?",
        "options": [
          "Distances become exponentially smaller, causing numerical underflow.",
          "The difference between the distance to the nearest and farthest neighbor becomes negligible.",
          "Computational complexity decreases because data points are further apart.",
          "Feature vectors become linearly dependent as dimensions increase."
        ],
        "correct_index": 1,
        "rationale": "Slide 17 notes that distance-based similarities become 'non-discriminative' because in high-dimensional space, all points tend to become equidistant.",
        "distractor_analysis": {
          "0": "Volume grows, so distances generally appear to increase, but the relative difference disappears.",
          "1": "Correct. This makes 'nearness' lose its meaning for classification.",
          "2": "Computational complexity increases, it does not decrease.",
          "3": "Dimensionality increases the independence of vectors unless they are redundant."
        }
      },
      {
        "id": 8,
        "topic": "Curse of Dimensionality",
        "difficulty": "analysis",
        "question": "Considering the volume of a unit sphere (r=1), what happens to the data distribution as the number of dimensions (D) increases toward infinity?",
        "options": [
          "Data concentrates almost entirely at the center of the sphere.",
          "Data is distributed uniformly throughout the volume.",
          "Data concentrates in a thin shell near the surface of the sphere.",
          "The volume of the sphere collapses to zero."
        ],
        "correct_index": 2,
        "rationale": "Slide 17's formula 1 - (1 - ε)^D shows that as D increases, the fraction of volume in the outer shell (between 1-ε and 1) approaches 1.",
        "distractor_analysis": {
          "0": "Mathematically, the 'center' volume fraction approaches zero in high D.",
          "1": "Uniformity is lost as almost all volume shifts to the shell.",
          "2": "Correct. This is a counter-intuitive property of high-dimensional space.",
          "3": "The volume doesn't collapse; our ability to populate it with representative data does."
        }
      },
      {
        "id": 9,
        "topic": "Cross Validation",
        "difficulty": "recall",
        "question": "In N-fold cross-validation, what is the ideal frequency of each class in a single fold?",
        "options": [
          "One class should dominate each fold to test model robustness.",
          "Classes should be randomly distributed without regard to frequency.",
          "Each fold should contain exactly one instance of each class.",
          "Proportional to its frequency in the full dataset."
        ],
        "correct_index": 3,
        "rationale": "Slide 18 states that ideally, class frequency in a fold should be proportional to its frequency in the full dataset (stratification).",
        "distractor_analysis": {
          "0": "This would bias the training/testing phase of that fold.",
          "1": "Random distribution is the baseline, but 'proportional' is the listed ideal.",
          "2": "This is only possible if all classes have equal counts and N matches that count.",
          "3": "Correct. This ensures each fold is a representative 'mini-version' of the whole."
        }
      },
      {
        "id": 10,
        "topic": "Bootstrapping",
        "difficulty": "analysis",
        "question": "What is a primary difference between the training set in N-fold Cross-Validation versus Bootstrapping?",
        "options": [
          "Bootstrapping samples without replacement, while CV samples with replacement.",
          "Bootstrapping allows the same instance to appear multiple times in the training set.",
          "CV results in a training set that is ~63.2% of the total data.",
          "Bootstrapping ensures that every instance is used exactly once for training."
        ],
        "correct_index": 1,
        "rationale": "Slide 19 defines Bootstrapping as sampling 'with replacement', meaning instances can be repeated in the training set.",
        "distractor_analysis": {
          "0": "It is the opposite; CV is an exhaustive partition, Bootstrap uses replacement.",
          "1": "Correct. This is the defining characteristic of the Bootstrap method.",
          "2": "Bootstrapping results in ~63.2% *unique* instances, CV uses (N-1)/N (e.g., 90%).",
          "3": "CV ensures usage across folds; Bootstrapping is stochastic and may omit instances from training entirely."
        }
      },
      {
        "id": 11,
        "topic": "Error Types",
        "difficulty": "recall",
        "question": "Which error type represents the theoretical minimum error rate that any classifier can achieve on a given task?",
        "options": [
          "Training error",
          "Test error",
          "Bayes error",
          "Generalized error"
        ],
        "correct_index": 2,
        "rationale": "Slide 22 defines the Bayes error as the result of the 'Bayes optimal classifier' which minimizes the probability of misclassification.",
        "distractor_analysis": {
          "0": "Training error can often be zero (overfitting) but is not the theoretical limit of accuracy.",
          "1": "Test error is an estimate of real-world performance for a specific model.",
          "2": "Correct. It is the error due to overlapping class distributions.",
          "3": "Generalized error is the expected error on unseen data for a specific algorithm."
        }
      },
      {
        "id": 12,
        "topic": "Loss Functions",
        "difficulty": "application",
        "question": "In a medical diagnosis model for a severe disease, if the cost of missing a sick patient is much higher than the cost of a false alarm, which matrix element must be weighted more heavily?",
        "options": [
          "Ground Truth: Disease / Predicted: Disease",
          "Ground Truth: OK / Predicted: OK",
          "Ground Truth: Disease / Predicted: OK",
          "Ground Truth: OK / Predicted: Disease"
        ],
        "correct_index": 2,
        "rationale": "Missing a sick patient is a False Negative. Slide 23's loss matrix example shows 'Ground Truth: disease / Predicted: ok' with a high value (1000).",
        "distractor_analysis": {
          "0": "This is a True Positive, which should have zero or low loss.",
          "1": "This is a True Negative, which should have zero or low loss.",
          "2": "Correct. This is a False Negative (miss), the most dangerous error in this scenario.",
          "3": "This is a False Positive (false alarm), which is less critical than a miss here."
        }
      },
      {
        "id": 13,
        "topic": "Model Selection",
        "difficulty": "analysis",
        "question": "When comparing two models, h and h', using k-fold cross-validation, what statistical distribution is typically used to determine if their error means are significantly different?",
        "options": [
          "Normal distribution",
          "Chi-square distribution",
          "t-distribution with k-1 degrees of freedom",
          "Poisson distribution"
        ],
        "correct_index": 2,
        "rationale": "Slide 25 states that the difference in errors is t-distributed with k-1 degrees of freedom.",
        "distractor_analysis": {
          "0": "While errors are approx. normal, the *difference* in sample means follows t.",
          "1": "Chi-square is used for feature independence tests, not mean error comparison.",
          "2": "Correct. This is the standard for the paired t-test logic presented.",
          "3": "Poisson is for count data, not continuous error rate averages."
        }
      },
      {
        "id": 14,
        "topic": "Accuracy",
        "difficulty": "analysis",
        "question": "Why might a classifier with 99% accuracy still be considered 'bad' or misleading?",
        "options": [
          "Because accuracy does not account for the variance of the features.",
          "If the dataset is highly imbalanced (e.g., 99% of instances belong to one class).",
          "If the classifier's precision is equal to its recall.",
          "If the decision threshold is set exactly at 0.5."
        ],
        "correct_index": 1,
        "rationale": "Slide 26 asks 'Is an accuracy of 99% good?'. In imbalanced data, a dummy classifier predicting only the majority class would hit 99% accuracy without learning.",
        "distractor_analysis": {
          "0": "Variance is a feature property, but accuracy's failure is a class distribution problem.",
          "1": "Correct. This is the 'accuracy paradox' in skewed datasets.",
          "2": "Equal precision and recall often indicate a well-balanced model.",
          "3": "A 0.5 threshold is standard; accuracy's failure is independent of the threshold value itself."
        }
      },
      {
        "id": 15,
        "topic": "Precision vs. Recall",
        "difficulty": "application",
        "question": "A search engine wants to ensure that every result it shows is highly relevant, even if it misses some relevant documents. Which metric should it prioritize?",
        "options": [
          "Recall",
          "Accuracy",
          "Precision",
          "Sensitivity"
        ],
        "correct_index": 2,
        "rationale": "Slide 27: Precision = TP / (TP + FP). It represents the fraction of predicted positives that are actually positive. High precision means low False Positives.",
        "distractor_analysis": {
          "0": "Recall (Sensitivity) prioritizes finding *all* relevant documents, potentially increasing noise.",
          "1": "Accuracy is too general and doesn't distinguish between the types of errors.",
          "2": "Correct. Precision measures the 'purity' of the positive predictions.",
          "3": "Sensitivity is a synonym for Recall, which focuses on completeness."
        }
      },
      {
        "id": 16,
        "topic": "F1-measure",
        "difficulty": "recall",
        "question": "The F1-measure is described as which type of mathematical mean between Precision and Recall?",
        "options": [
          "Arithmetic mean",
          "Geometric mean",
          "Harmonic mean",
          "Weighted average"
        ],
        "correct_index": 2,
        "rationale": "Slide 29 explicitly states: 'The F1-score is the harmonic mean between Precision and Recall.'",
        "distractor_analysis": {
          "0": "Arithmetic mean would over-reward a model with one very high and one very low score.",
          "1": "Geometric mean is used in other contexts but not the standard F1 formula.",
          "2": "Correct. The harmonic mean is sensitive to low values, requiring both to be high.",
          "3": "While it can be weighted (F-alpha), the standard F1 is specifically the harmonic mean."
        }
      },
      {
        "id": 17,
        "topic": "Precision-Recall Curve",
        "difficulty": "analysis",
        "question": "Which condition is required to plot a Precision-Recall curve rather than just a single point?",
        "options": [
          "The dataset must have more than two classes.",
          "The model must provide a continuous prediction probability/score to vary a threshold.",
          "The precision must be strictly greater than the recall.",
          "Cross-validation must be performed at least 10 times."
        ],
        "correct_index": 1,
        "rationale": "Slide 30 states: 'With decreasing decision threshold, plot precision recall values'. This requires a model that outputs scores, not just hard labels.",
        "distractor_analysis": {
          "0": "Curves can be used for binary or multi-class (one-against-all).",
          "1": "Correct. Without a threshold to vary, you only have one Precision/Recall pair.",
          "2": "Precision and recall can be in any relationship.",
          "3": "Cross-validation is a validation strategy, not a plotting requirement."
        }
      },
      {
        "id": 18,
        "topic": "ROC Curve",
        "difficulty": "recall",
        "question": "In an ROC curve, what are the axes used for plotting?",
        "options": [
          "Precision (y) vs. Recall (x)",
          "Sensitivity (y) vs. 1-Specificity (x)",
          "True Positive Rate (y) vs. Precision (x)",
          "Accuracy (y) vs. Error Rate (x)"
        ],
        "correct_index": 1,
        "rationale": "Slide 31 labels the y-axis as Sensitivity (TPR) and the x-axis as 1 - Specificity (FPR).",
        "distractor_analysis": {
          "0": "This is a Precision-Recall curve.",
          "1": "Correct. This shows the trade-off between benefits (TPR) and costs (FPR).",
          "2": "This combines axes from two different curve types.",
          "3": "Accuracy vs Error is redundant and not a standard curve."
        }
      },
      {
        "id": 19,
        "topic": "AUC",
        "difficulty": "analysis",
        "question": "What does the Area Under the Curve (AUC) fundamentally represent regarding a model's capabilities?",
        "options": [
          "The probability that the model is 100% accurate.",
          "The ranking accuracy of the model.",
          "The optimal decision threshold for the specific dataset.",
          "The ratio of training error to test error."
        ],
        "correct_index": 1,
        "rationale": "Slide 31 explicitly states that the AUC 'represents the ranking accuracy'.",
        "distractor_analysis": {
          "0": "AUC measures performance across all thresholds, not a single probability of perfection.",
          "1": "Correct. It measures how well the model separates the scores of different classes.",
          "2": "AUC is threshold-independent; it summarizes the curve generated by *all* thresholds.",
          "3": "AUC has nothing to do with the ratio of training/test error."
        }
      },
      {
        "id": 20,
        "topic": "Metric Selection",
        "difficulty": "application",
        "question": "If you need to perform a 'deeper analysis of thresholds' for a classifier, which tool should you use according to the summary slide?",
        "options": [
          "Confusion Matrix",
          "F1-score",
          "ROC curves",
          "Specific Accuracy"
        ],
        "correct_index": 2,
        "rationale": "Slide 33 categorizes 'ROC curves' and 'Precision-recall curves' under 'For deeper analysis of thresholds'.",
        "distractor_analysis": {
          "0": "Confusion matrices are for a single fixed threshold.",
          "1": "F1-score is a single scalar for a fixed threshold.",
          "2": "Correct. Curves visualize the impact of changing the threshold.",
          "3": "Accuracy is a single point metric if the threshold is not an issue."
        }
      },
      {
        "id": 21,
        "topic": "Discretization",
        "difficulty": "analysis",
        "question": "Which method of discretization relies on the target class labels to determine bin boundaries?",
        "options": [
          "Distance-based binning",
          "Unsupervised clustering",
          "Entropy-based splitting",
          "Equal-width binning"
        ],
        "correct_index": 2,
        "rationale": "Slide 8 categorizes 'Dependency, entropy' and 'Accuracy, error' under 'Supervised' discretization, which uses class information.",
        "distractor_analysis": {
          "0": "Distance/similarity is categorized under Unsupervised.",
          "1": "Clustering is explicitly categorized under Unsupervised.",
          "2": "Correct. Entropy splits are calculated based on class labels.",
          "3": "Equal-width is a standard unsupervised strategy not involving labels."
        }
      },
      {
        "id": 22,
        "topic": "Terminology",
        "difficulty": "recall",
        "question": "How is an 'instance' abstractly described in the context of supervised learning according to the slides?",
        "options": [
          "As a single class label",
          "Through a feature vector with feature values",
          "As a set of similar classes",
          "As a collection of training sets"
        ],
        "correct_index": 1,
        "rationale": "Slide 4 defines an instance as: 'Abstractly described through a feature vector with feature values, x = (x1, ..., xn)'.",
        "distractor_analysis": {
          "0": "A class label is assigned to an instance, not its description.",
          "1": "Correct. This is the standard vector representation.",
          "2": "A class is a set of similar instances, not the other way around.",
          "3": "Training sets are collections of instances, not an abstract description of one."
        }
      },
      {
        "id": 23,
        "topic": "Feature Characteristics",
        "difficulty": "application",
        "question": "Which measure of central tendency is appropriate for a 'Categorical' feature like 'Eye Color'?",
        "options": [
          "Mean",
          "Median",
          "Mode",
          "Standard Deviation"
        ],
        "correct_index": 2,
        "rationale": "Slide 6 lists 'mode' as the tendency measure for Categorical features and 'n/a' for others.",
        "distractor_analysis": {
          "0": "Mean requires a scale and order (continuous).",
          "1": "Median requires at least an order (ordinal/continuous).",
          "2": "Correct. Mode just identifies the most frequent category.",
          "3": "Standard deviation requires a scale/distance."
        }
      },
      {
        "id": 24,
        "topic": "Model Robustness",
        "difficulty": "analysis",
        "question": "Which of these classifications algorithms is categorized as 'Non-linear' in the provided slides?",
        "options": [
          "Naive Bayes",
          "Logistic Regression",
          "Support Vector Machines",
          "K-Nearest Neighbors"
        ],
        "correct_index": 3,
        "rationale": "Slide 11 lists K-Nearest Neighbors under 'Non-linear classification models'.",
        "distractor_analysis": {
          "0": "Naive Bayes is listed under Linear (Slide 10).",
          "1": "Logistic Regression is listed under Linear (Slide 10).",
          "2": "Support Vector Machines (basic) is listed under Linear (Slide 10).",
          "3": "Correct. KNN relies on local neighborhoods, creating non-linear boundaries."
        }
      },
      {
        "id": 25,
        "topic": "Validation",
        "difficulty": "recall",
        "question": "In the training and validation workflow, what is the 'Test set' used for specifically?",
        "options": [
          "To learn the model parameters",
          "To choose between different feature types",
          "To validate the model with hidden classes",
          "To perform discretization of continuous features"
        ],
        "correct_index": 2,
        "rationale": "Slide 9 and 14 state the test set contains instances where classes are 'hidden to test the classifier' for validation.",
        "distractor_analysis": {
          "0": "The training set is used to learn parameters.",
          "1": "Feature selection is done before or during training, not on the test set.",
          "2": "Correct. It simulates real-world performance on unseen data.",
          "3": "Discretization is a preprocessing step applied to all data or during training."
        }
      },
      {
        "id": 26,
        "topic": "Overfitting",
        "difficulty": "application",
        "question": "Why does high dimensionality (many features) often lead to overfitting?",
        "options": [
          "It makes the training set more representative of the population.",
          "It allows the model to find coincidental patterns in the training noise.",
          "It reduces the space the model needs to search for a solution.",
          "It forces the model to ignore outliers."
        ],
        "correct_index": 1,
        "rationale": "Slide 16 notes that in high dimensions, training data becomes quickly 'non-representative', leading to overfitting on noise.",
        "distractor_analysis": {
          "0": "High dimensionality actually makes training data *less* representative.",
          "1": "Correct. More features provide more 'hooks' to memorize random noise.",
          "2": "The instance space grows exponentially, making the search much harder.",
          "3": "High dimensions typically make models *more* sensitive to specific instance variations."
        }
      },
      {
        "id": 27,
        "topic": "N-fold Cross Validation",
        "difficulty": "application",
        "question": "In a 10-fold cross-validation, how many times is a specific instance used for 'testing' (validation)?",
        "options": [
          "9 times",
          "10 times",
          "1 time",
          "It depends on the weighting of the parameters"
        ],
        "correct_index": 2,
        "rationale": "In N-fold CV, the dataset is split into N folds. Each fold serves as the test set exactly once while the others serve as training.",
        "distractor_analysis": {
          "0": "An instance is used for *training* 9 times in 10-fold CV.",
          "1": "An instance is only in the test set of one specific fold.",
          "2": "Correct. It is tested once to provide an unbiased error estimate.",
          "3": "The error estimation logic (Slide 18) is independent of the split mechanics."
        }
      },
      {
        "id": 28,
        "topic": "Bootstrapping",
        "difficulty": "analysis",
        "question": "For a dataset with 'n' elements, why is the expected fraction of unique instances in a bootstrap training set approximately 0.632 as n goes to infinity?",
        "options": [
          "Because 36.8% of the data is inherently noisy and discarded.",
          "It is the limit of (1 - 1/n)^n subtracted from 1.",
          "Because the model only needs 63.2% of data to converge.",
          "It represents the Golden Ratio of data science sampling."
        ],
        "correct_index": 1,
        "rationale": "Slide 19 shows the math: 1 - lim (1 - 1/n)^n = 1 - 1/e ≈ 0.632.",
        "distractor_analysis": {
          "0": "The 36.8% are simply the instances not selected due to random replacement.",
          "1": "Correct. This is the probability of an element being picked at least once.",
          "2": "There is no theoretical requirement for convergence at this specific percentage.",
          "3": "This is a humorous distractor with no scientific basis."
        }
      },
      {
        "id": 29,
        "topic": "Generalized Error",
        "difficulty": "recall",
        "question": "Generalized error is defined on Slide 21 as the expected value of which other error?",
        "options": [
          "Training error",
          "Test error",
          "Bayes error",
          "Absolute loss"
        ],
        "correct_index": 1,
        "rationale": "Slide 21 explicitly shows: Generalized error = E(test error).",
        "distractor_analysis": {
          "0": "Training error is often biased and not a good proxy for generalization.",
          "1": "Correct. It reflects how the model will perform on the broader population.",
          "2": "Bayes error is a theoretical lower bound, not the model's expected error.",
          "3": "Absolute loss is a specific cost function used to *calculate* error."
        }
      },
      {
        "id": 30,
        "topic": "Loss Functions",
        "difficulty": "recall",
        "question": "Which loss function behaves as an indicator function, returning 1 for misclassification and 0 for correct classification?",
        "options": [
          "Absolute loss",
          "Quadratic loss",
          "0-1 loss",
          "Information loss"
        ],
        "correct_index": 2,
        "rationale": "Slide 24 defines 0-1 loss: l(y, t) = 1 if y ≠ t, and 0 if y = t.",
        "distractor_analysis": {
          "0": "Absolute loss measures the magnitude of the difference (y-t).",
          "1": "Quadratic loss squares the difference, penalizing larger errors more.",
          "2": "Correct. This is the simplest binary error metric.",
          "3": "Information loss uses log-likelihoods."
        }
      },
      {
        "id": 31,
        "topic": "Confusion Matrix",
        "difficulty": "recall",
        "question": "In the confusion matrix, how are 'False Positives' defined?",
        "options": [
          "Actual class is C, predicted is C-bar",
          "Actual class is C-bar, predicted is C",
          "Actual class is C, predicted is C",
          "Actual class is C-bar, predicted is C-bar"
        ],
        "correct_index": 1,
        "rationale": "Slide 26: False Positives (FP) occur when the predicted value is C but the actual value is C-bar.",
        "distractor_analysis": {
          "0": "This is a False Negative.",
          "1": "Correct. The model 'falsely' predicted the 'positive' class C.",
          "2": "This is a True Positive.",
          "3": "This is a True Negative."
        }
      },
      {
        "id": 32,
        "topic": "Recall",
        "difficulty": "analysis",
        "question": "What does Recall (also known as Sensitivity) fundamentally measure?",
        "options": [
          "The accuracy of the positive predictions made by the model.",
          "The model's ability to identify all actual positive instances.",
          "The fraction of negative instances correctly identified.",
          "The trade-off between False Positives and True Negatives."
        ],
        "correct_index": 1,
        "rationale": "Slide 27/28: Recall = TP / (TP + FN). It measures how many of the 'actual' positives were captured.",
        "distractor_analysis": {
          "0": "This describes Precision.",
          "1": "Correct. It's about 'coverage' of the actual class C.",
          "2": "This describes Specificity.",
          "3": "This describes a relationship found in the ROC x-axis, not Recall itself."
        }
      },
      {
        "id": 33,
        "topic": "Specificity",
        "difficulty": "recall",
        "question": "According to the slides, what is the formula for Specificity?",
        "options": [
          "TP / (TP + FN)",
          "TN / (TN + FP)",
          "TP / (TP + FP)",
          "TN / (TN + FN)"
        ],
        "correct_index": 1,
        "rationale": "Slide 28: Specificity(h) = TN / (TN + FP).",
        "distractor_analysis": {
          "0": "This is Recall (Sensitivity).",
          "1": "Correct. It measures the 'purity' of the negative class detection.",
          "2": "This is Precision.",
          "3": "This is an incorrect combination of terms."
        }
      },
      {
        "id": 34,
        "topic": "Precision-Recall Curve",
        "difficulty": "analysis",
        "question": "On a Precision-Recall curve, where is the point of 'better performance' typically located?",
        "options": [
          "Bottom-left (0,0)",
          "Bottom-right (1,0)",
          "Top-left (0,1)",
          "Top-right (1,1)"
        ],
        "correct_index": 3,
        "rationale": "As per the graph on Slide 30, better performance is in the upper right quadrant where both Precision and Recall are 1.",
        "distractor_analysis": {
          "0": "This is the worst performance.",
          "1": "This represents perfect recall but zero precision.",
          "2": "This represents perfect precision but zero recall.",
          "3": "Correct. It represents a model with no false positives and no false negatives."
        }
      },
      {
        "id": 35,
        "topic": "ROC vs PR Curve",
        "difficulty": "analysis",
        "question": "Which of these is ONLY useful if the model's decision threshold can be varied?",
        "options": [
          "F1-measure",
          "Accuracy",
          "Precision-Recall curve",
          "Specificity"
        ],
        "correct_index": 2,
        "rationale": "Slide 33 notes that PR curves and ROC curves are 'For deeper analysis of thresholds'. Point metrics like F1 or Accuracy don't require varying a threshold.",
        "distractor_analysis": {
          "0": "F1 is calculated for a single threshold.",
          "1": "Accuracy is a single point on the confusion matrix.",
          "2": "Correct. A curve is a collection of points generated by threshold variance.",
          "3": "Specificity is a fixed value once the threshold is chosen."
        }
      },
      {
        "id": 36,
        "topic": "Feature Selection Rules",
        "difficulty": "recall",
        "question": "What is 'Rule 2' of feature selection and transformation according to Slide 5?",
        "options": [
          "Get to know your data",
          "Eliminate all categorical features",
          "Make plausible assumptions (e.g., normal distribution)",
          "Always prioritize mutual information"
        ],
        "correct_index": 2,
        "rationale": "Slide 5 lists Rule 1: Get to know your data; Rule 2: Make plausible assumptions.",
        "distractor_analysis": {
          "0": "This is Rule 1.",
          "1": "Categorical features are often essential and should not be eliminated by default.",
          "2": "Correct. Assumptions about distribution help in choosing the right transformation.",
          "3": "Mutual information is a tool, not a fundamental 'rule' of the process."
        }
      },
      {
        "id": 37,
        "topic": "Training Data",
        "difficulty": "application",
        "question": "Which scenario is most likely to lead to 'non-representative' training data?",
        "options": [
          "A dataset where features are independent.",
          "A dataset with low dimensionality and many instances.",
          "A dataset where the instance space grows exponentially relative to samples.",
          "A dataset that follows a Pareto principle for income distribution."
        ],
        "correct_index": 2,
        "rationale": "Slide 16 states that with increasing dimensions, the space grows exponentially, causing training data to become non-representative.",
        "distractor_analysis": {
          "0": "Independence is generally a positive feature trait.",
          "1": "This is the ideal scenario for a representative dataset.",
          "2": "Correct. This is a core part of the Curse of Dimensionality.",
          "3": "The Pareto principle is a valid assumption (Rule 2) and doesn't imply non-representativeness by itself."
        }
      },
      {
        "id": 38,
        "topic": "Model Selection",
        "difficulty": "analysis",
        "question": "If you use Bootstrapping for model selection, how is the total error 'err' calculated to avoid over-optimism?",
        "options": [
          "It is simply the average error on the training set.",
          "It is the error on the 36.8% test set only.",
          "It is a weighted sum of the test error (0.632) and training error (0.368).",
          "It is the sum of the Bayes error and the training error."
        ],
        "correct_index": 2,
        "rationale": "Slide 20 provides the formula: err = 1/m * Σ (0.632 * err_test + 0.368 * err_training).",
        "distractor_analysis": {
          "0": "Training error alone is overly optimistic.",
          "1": "Using only the test error ignores the information in the training split.",
          "2": "Correct. This specific weighting (0.632/0.368) is used to balance the estimation.",
          "3": "Bayes error is unknown and not used in this validation formula."
        }
      },
      {
        "id": 39,
        "topic": "Any-of Classification",
        "difficulty": "application",
        "question": "In an 'Any-of' classification scenario, what is the 'Typical solution' for making decisions across classes?",
        "options": [
          "The decision of one classifier influences the next in a sequence.",
          "The decision of one classifier has no influence on the others.",
          "Classes are merged until only two remain.",
          "The class with the highest probability is chosen, and all others are discarded."
        ],
        "correct_index": 1,
        "rationale": "Slide 13 states for Any-of: 'The decision of one classifier has no influence on the decisions of the other classifiers.'",
        "distractor_analysis": {
          "0": "This describes a hierarchical or chained classifier.",
          "1": "Correct. Since an instance can be in many or no classes, decisions must be independent.",
          "2": "This would change the problem into binary classification.",
          "3": "This describes 'One-of' classification."
        }
      },
      {
        "id": 40,
        "topic": "Discrete Features",
        "difficulty": "analysis",
        "question": "A dataset contains 'House Numbers'. Why are these classified as 'Ordinal' rather than 'Categorical' or 'Continuous' in these slides?",
        "options": [
          "Because they can be ordered but do not have a meaningful scale/distance.",
          "Because you can perform mathematical addition on them.",
          "Because they represent a real-valued height or weight.",
          "Because they have no ordering or scale whatsoever."
        ],
        "correct_index": 0,
        "rationale": "Slide 6 explicitly lists 'house numbers' as Ordinal because they 'can be ordered but do not have a scale'.",
        "distractor_analysis": {
          "0": "Correct. Number 10 is after 8, but the 'distance' between them doesn't represent a physical quantity like 2 meters.",
          "1": "Adding house numbers (10+12=22) usually results in a meaningless value, indicating a lack of scale.",
          "2": "These are continuous features, which house numbers are not.",
          "3": "This describes Categorical features (e.g., Eye Color)."
        }
      },
      {
        "id": 41,
        "topic": "Feature Selection",
        "difficulty": "recall",
        "question": "Which statistical test is mentioned as an example for choosing 'good' features based on independence?",
        "options": [
          "Student's t-test",
          "Chi-square (χ2)-test",
          "F-test",
          "Z-test"
        ],
        "correct_index": 1,
        "rationale": "Slide 5 mentions 'χ2-test of independence' as a tool for feature selection.",
        "distractor_analysis": {
          "0": "t-test is used for comparing model error means (Slide 25).",
          "1": "Correct. It helps determine if a feature is independent of the class.",
          "2": "F-test is for variance comparison, not listed here for selection.",
          "3": "Z-test is for large sample mean comparison, not listed for selection."
        }
      },
      {
        "id": 42,
        "topic": "One-of vs. Any-of",
        "difficulty": "recall",
        "question": "In 'One-of' classification, what does 'k' represent?",
        "options": [
          "The number of instances",
          "The number of features",
          "The number of classes",
          "The number of neighbors"
        ],
        "correct_index": 2,
        "rationale": "Slide 12: 'For k > 2 different classes C1, ..., Ck'.",
        "distractor_analysis": {
          "0": "Instances are denoted by 'x' or 'n'.",
          "1": "Features are usually 'x_i' elements.",
          "2": "Correct. It signifies the cardinality of the label set.",
          "3": "This is specific to the KNN algorithm."
        }
      },
      {
        "id": 43,
        "topic": "Cross Validation",
        "difficulty": "recall",
        "question": "What is 'Leave-one-out cross validation' as defined in the slides?",
        "options": [
          "A method where one feature is removed at a time.",
          "A case of N-fold CV where each fold is a single instance.",
          "A method that ignores the most frequent class.",
          "A technique to remove outliers from the training set."
        ],
        "correct_index": 1,
        "rationale": "Slide 18: 'Leave-one-out cross validation: N-fold cross validation where each fold is a single instance'.",
        "distractor_analysis": {
          "0": "This is 'Leave-one-out feature selection', a different concept.",
          "1": "Correct. If you have 100 instances, you do 100-fold CV.",
          "2": "This is a form of data cleaning or balancing, not LOOCV.",
          "3": "LOOCV uses all data; it doesn't remove outliers permanently."
        }
      },
      {
        "id": 44,
        "topic": "Overfitting",
        "difficulty": "recall",
        "question": "According to Slide 15, which of the following is NOT a listed cause of overfitting?",
        "options": [
          "Small training set",
          "High dimensionality",
          "Non-representative training instances",
          "Too few parameters in the model"
        ],
        "correct_index": 3,
        "rationale": "Too few parameters usually leads to underfitting. The slide lists 'Parameters are set to the best performing values on the training set' (over-optimization) as a cause.",
        "distractor_analysis": {
          "0": "Listed as a primary cause.",
          "1": "Listed as a primary cause.",
          "2": "Listed as a primary cause.",
          "3": "Correct. This is generally associated with underfitting, not overfitting."
        }
      },
      {
        "id": 45,
        "topic": "Error Types",
        "difficulty": "analysis",
        "question": "If a model has zero Training Error but a high Test Error, what is the most likely diagnosis?",
        "options": [
          "The model has reached the Bayes optimal limit.",
          "The model is suffering from the Curse of Dimensionality / Overfitting.",
          "The test set is too small.",
          "The features were not correctly discretized."
        ],
        "correct_index": 1,
        "rationale": "Slide 15/21: A large gap between training performance and test performance is the definition of overfitting.",
        "distractor_analysis": {
          "0": "Bayes error affects both training and test error (you can't go below it).",
          "1": "Correct. It memorized the training data but failed to generalize.",
          "2": "A small test set leads to unreliable error estimates, but a *high* error specifically suggests overfitting.",
          "3": "Incorrect discretization might lower overall performance, but the training/test gap is the hallmark of overfitting."
        }
      },
      {
        "id": 46,
        "topic": "Metric Selection",
        "difficulty": "application",
        "question": "Which measure would you use if you want a single metric that balances both the 'purity' of positive predictions and the 'completeness' of positive captures?",
        "options": [
          "Specificity",
          "F1-measure",
          "Accuracy",
          "AUC"
        ],
        "correct_index": 1,
        "rationale": "Slide 29: F1-measure combines Precision (purity) and Recall (completeness) into one harmonic mean.",
        "distractor_analysis": {
          "0": "Specificity focuses on the negative class only.",
          "1": "Correct. It's the standard for balancing Precision and Recall.",
          "2": "Accuracy treats all types of errors equally and can be misleading.",
          "3": "AUC measures ranking performance across all thresholds, not a single balance of purity/completeness at a fixed point."
        }
      },
      {
        "id": 47,
        "topic": "Decision Thresholds",
        "difficulty": "analysis",
        "question": "What happens to the number of 'False Positives' as you decrease the decision threshold in a classification model?",
        "options": [
          "They stay the same.",
          "They will always decrease.",
          "They will likely increase.",
          "They become True Negatives."
        ],
        "correct_index": 2,
        "rationale": "Decreasing the threshold makes the model more 'lenient', classifying more instances as positive. This increases both TP and FP (Slide 31/32 ROC logic).",
        "distractor_analysis": {
          "0": "Thresholds directly change the count of predicted positives.",
          "1": "Decreasing the threshold increases the volume of positives, increasing error risk.",
          "2": "Correct. More instances cross the lower bar, including incorrect ones.",
          "3": "No, they are predicted as Positives, so they can't be True Negatives."
        }
      },
      {
        "id": 48,
        "topic": "Multi-class Accuracy",
        "difficulty": "recall",
        "question": "How can overall performance be reported for multi-class classification according to the 'one-against-all' summary?",
        "options": [
          "As the minimum precision across all classes.",
          "As a weighted average of metrics across all classes.",
          "By only reporting the accuracy of the most frequent class.",
          "By multiplying the errors of each independent classifier."
        ],
        "correct_index": 1,
        "rationale": "Slide 37: 'Overall performance could be reported as the weighted average of precision, recall, accuracy, error...' based on class proportions.",
        "distractor_analysis": {
          "0": "Minimum precision is a specific 'worst-case' metric, not the standard overall report.",
          "1": "Correct. Weighting by class proportion ensures a fair summary.",
          "2": "This would ignore the model's failure on minority classes.",
          "3": "Multiplication has no logical basis in error reporting here."
        }
      },
      {
        "id": 49,
        "topic": "Feature Ordering",
        "difficulty": "recall",
        "question": "In the 'Features' table (Slide 6), which feature type does NOT support an 'Order' property?",
        "options": [
          "Categorical",
          "Ordinal",
          "Continuous",
          "Discrete"
        ],
        "correct_index": 0,
        "rationale": "The table on Slide 6 has an 'X' under 'Order' for Categorical features.",
        "distractor_analysis": {
          "0": "Correct. Categories (like Colors) have no inherent mathematical ranking.",
          "1": "Ordinal features are defined by their ability to be ordered.",
          "2": "Continuous features are real-valued and ordered.",
          "3": "Discrete is a broad category including Ordinal, which *is* ordered."
        }
      },
      {
        "id": 50,
        "topic": "Metric Suitability",
        "difficulty": "analysis",
        "question": "If your goal is 'deeper analysis of thresholds', which of these measures is explicitly EXCLUDED from that list in the provided slides?",
        "options": [
          "ROC curves",
          "Precision-recall curves",
          "Hypothesis testing",
          "Accuracy"
        ],
        "correct_index": 3,
        "rationale": "Slide 33 lists ROC, PR curves, and Hypothesis testing for 'deeper analysis of thresholds', but lists Accuracy under 'If threshold analysis is not an issue'.",
        "distractor_analysis": {
          "0": "Included in the deeper analysis list.",
          "1": "Included in the deeper analysis list.",
          "2": "Included in the deeper analysis list.",
          "3": "Correct. Accuracy is a static point metric."
        }
      }
    ]
  }
}
